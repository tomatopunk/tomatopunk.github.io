<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Tomato Punk</title>
  
  <subtitle>To see a world in a grain of sand,And a heaven in a wild flower</subtitle>
  <link href="http://murph.site/atom.xml" rel="self"/>
  
  <link href="http://murph.site/"/>
  <updated>2021-09-26T06:48:27.286Z</updated>
  <id>http://murph.site/</id>
  
  <author>
    <name>Murphy</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>NewSQL-并发控制</title>
    <link href="http://murph.site/2021/03/12/newsql-concurrency-control/"/>
    <id>http://murph.site/2021/03/12/newsql-concurrency-control/</id>
    <published>2021-03-12T09:55:51.000Z</published>
    <updated>2021-09-26T06:48:27.286Z</updated>
    
    <content type="html"><![CDATA[<p>NewSQL-并发控制原理解析</p><a id="more"></a><p>Concurrency control scheme is the most salient and important implementation detail of a transaction processing DBMS as it affects almost all aspects of the system. Concurrency control permits end-users to access a database in a multi-program SIGMOD Record, June 2016 (Vol. 45, No. 2) 49 med fashion while preserving the llusion that each of them is executing their transaction alone on a dedicated system. It essentially provides the atomicity and isolation guarantees in the system, and as such it influences the entire system’s behavior.</p><p>Beyond which scheme a system uses, another important aspect of the design of a distributed DBMS is whether the system uses a centralized or decentralized transaction coordination protocol. In a system with a centralized coordinator, all transactions’ operations have to go through the coordinator,<br>which then makes decisions about whether transactions are allowed to proceed or not. This is the same approach used by the TP monitors of the 1970–1980s (e.g., IBM CICS, Oracle Tuxedo). In a decentralized system, each node maintains the state of transactions that access the data that it manages. The nodes then have to coordinate with each other to determine whether concurrent transactions conflict. A decentralized coordinator is better for scalability but requires that the clocks in the DBMS nodes are highly synchronized in order to generate a global ordering of transactions [1].</p><p>The first distributed DBMSs from the 1970–80s used twophase locking (2PL) schemes. SDD-1 was the first DBMS specifically designed for distributed transaction processing across a cluster of shared-nothing nodes managed by a centralized coordinator. IBM’s R* was similar to SDD-1, but the main difference was that the coordination of transactions in R* was completely decentralized; it used distributed 2PL protocol where transactions locked data items that they access directly at nodes. The distributed version of INGRES also used decentralized 2PL with centralized deadlock detection.</p><p>Almost all of the NewSQL systems based on new architectures eschew 2PL because the complexity of dealing with deadlocks. Instead, the current trend is to use variants of timestamp ordering (TO) concurrency control where the DBMS assumes that transactions will not execute interleaved operations that will violate serializable ordering. The most widely used protocol in NewSQL systems is decentralized multi-version concurrency control (MVCC) where the DBMS creates a new<br>version of a tuple in the database when it is updated by a transaction. Maintaining multiple versions potentially allows transactions to still complete even if another transaction updates the same tuples. It also allows for long-running, read-only transactions to not block on writers. This protocol is used in almost all of the NewSQL systems based on new architectures, like MemSQL, HyPer, HANA, and CockroachDB. Although there are engineering optimizations and tweaks that these systems use in their MVCC implementations to improve performance, the basic concepts of the scheme are not new. The first known work describing MVCC is a MIT PhD dissertation from 1979 [3], while the first commercial DBMSs to use it were Digital’s VAX Rdb and InterBase in the early 1980s. We note that the architecture of InterBase was designed by Jim Starkey, who is also the original designer of NuoDB and the failed Falcon MySQL storage engine project.</p><p>Other systems use a combination of 2PL and MVCC together. With this approach, transactions still have to acquire locks under the 2PL scheme to modify the database. When a transaction modifies a record, the DBMS creates a new version of that record just as it would with MVCC. This scheme allows read-only queries to avoid having to acquire locks and therefore not block on writing transactions. The most famous implementation of this approach is MySQL’s InnoDB, but it<br>is also used in both Google’s Spanner, NuoDB, and Clustrix. NuoDB improves on the original MVCC by employing a gossip protocol to broadcast versioning information between nodes.</p><p>All of the middleware and DBaaS services inherit the concurrency control scheme of their underlying DBMS architecture; since most of them use MySQL, this makes them 2PL with MVCC systems.</p><p>We regard the concurrency control implementation in Spanner (along with its descendants F1 [4] and SpannerSQL) as one of the most novel of the NewSQL systems. The actual scheme itself is based on the 2PL and MVCC combination developed in previous decades. But what makes Spanner different is that it uses hardware devices (e.g., GPS, atomic clocks) for high-precision clock synchronization. The DBMS uses these clocks to assign timestamps to transactions to enforce consistent views of its multi-version database over wide-area networks. CockroachDB also purports to provide the same kind of consistency for transactions across data centers as Spanner but without the use of atomic clocks. They instead rely on a hybrid clock protocol that combines loosely synchronized hardware clocks and logical counters [41].</p><p>Spanner is also noteworthy because it heralds Google’s return to using transactions for its most critical services. The authors of Spanner even remark that it is better to have their application programmers deal with performance problems due to overuse of transactions, rather than writing code to deal with the lack of transactions as one does with a NoSQL DBMS [1].</p><p>Lastly, the only commercial NewSQL DBMS that is not using some MVCC variant is VoltDB. This system still uses TO concurrency control, but instead of interleaving transactions like in MVCC, it schedules transactions to execute one-at-atime at each partition. It also uses a hybrid architecture where single-partition transactions are scheduled in a decentralized manner but multi-partition transactions are scheduled with a centralized coordinator. VoltDB orders transactions based on logical timestamps and then schedules them for execution at a partition when it is their turn. When a transaction executes at a partition, it has exclusive access to all of the data at that partition and thus the system does not have to set fine-grained locks and latches on its data structures. This allows transactions that only have to access a single partition to execute efficiently because there is no contention from other transactions. The downside of partition-based concurrency control is that it does not work well if transactions span multiple partitions because the network communication delays cause nodes to sit idle while they wait for messages. This partition-based concurrency is not a new idea. An early variant of it was first proposed in a 1992 paper by Hector Garcia-Molina [2] and implemented in the kdb system in late 1990s [5] and in HStore (which is the academic predecessor of VoltDB). </p><p>In general, we find that there is nothing significantly new about the core concurrency control schemes in NewSQL systems other than laudable engineering to make these algorithms work well in the context of modern hardware and distributed operating environments.</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><blockquote><p>[1] J. C. Corbett, J. Dean, M. Epstein, A. Fikes, C. Frost,J. Furman, S. Ghemawat, A. Gubarev, C. Heiser,P. Hochschild, W. Hsieh, S. Kanthak, E. Kogan, H. Li,A. Lloyd, S. Melnik, D. Mwaura, D. Nagle, S. Quinlan,R. Rao, L. Rolig, Y. Saito, M. Szymaniak, C. Taylor,R. Wang, and D. Woodford. Spanner: Google’s Globally-Distributed Database. In OSDI, 2012<br>[2] H. Garcia-Molina and K. Salem. Main memory database systems: An overview. IEEE Trans. on Knowl. and Data Eng., 4(6):509–516, Dec. 1992.<br>[3] D. P. Reed. Naming and synchronization in a decentralized computer system. PhD thesis, MIT, 1979<br>[4]  J. Shute, R. Vingralek, B. Samwel, B. Handy,C. Whipkey, E. Rollins, M. Oancea, K. Littlefield,D. Menestrina, S. Ellner, J. Cieslewicz, I. Rae,T. Stancescu,and H. Apte. F1: A distributed sql database that scales. Proc. VLDB Endow.,6(11):1068–1079, Aug. 2013.<br>[5] A. Whitney, D. Shasha, and S. Apter. High Volume Transaction Processing Without Concurrency Control,Two Phase Commit, SQL or C++. In HPTS, 1997.</p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;NewSQL-并发控制原理解析&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>大话线程(CLR视角)</title>
    <link href="http://murph.site/2020/11/10/c-clr-thread/"/>
    <id>http://murph.site/2020/11/10/c-clr-thread/</id>
    <published>2020-11-10T14:27:26.000Z</published>
    <updated>2021-09-26T06:48:27.286Z</updated>
    
    <content type="html"><![CDATA[<h3 id="原文信息"><a href="#原文信息" class="headerlink" title="原文信息"></a>原文信息</h3><p><strong>原文来自于CLR的概要设计系列中,线程篇</strong><br><strong>本文将会介绍一些关于<code>托管线程</code> <code>原生线程</code>,<code>线程生命周期</code>,<code>线程数据结构</code>等设计</strong><br><a href="https://github.com/dotnet/coreclr/blob/master/Documentation/botr/threading.md">原文:dotnet/coreclr</a></p><a id="more"></a><h2 id="Translating"><a href="#Translating" class="headerlink" title="Translating!!!"></a>Translating!!!</h2><ul><li><input checked="" disabled="" type="checkbox"> Managed Thread vs Native Threads</li><li><input checked="" disabled="" type="checkbox"> Data Structures</li><li><input checked="" disabled="" type="checkbox"> Thread Lifetimes</li><li><input checked="" disabled="" type="checkbox"> Suspension</li><li><input checked="" disabled="" type="checkbox"> Entering Cooperative Model</li><li><input checked="" disabled="" type="checkbox"> Suspending the EE</li><li><input checked="" disabled="" type="checkbox"> Hijacking</li><li><input disabled="" type="checkbox"> Thread Abort / AppDomain-Unload</li><li><input disabled="" type="checkbox"> Synchronization:Managed</li><li><input disabled="" type="checkbox"> Synchronization:Native</li><li><input disabled="" type="checkbox"> GC Mode</li><li><input disabled="" type="checkbox"> Crst</li><li><input disabled="" type="checkbox"> Special Threads</li><li><input disabled="" type="checkbox"> Finalizer Thread</li><li><input disabled="" type="checkbox"> GC Threads</li><li><input disabled="" type="checkbox"> Debugger Thread</li><li><input disabled="" type="checkbox"> Appdomain-Unload Thread</li><li><input disabled="" type="checkbox"> ThreadPool Threads</li></ul><h3 id="托管线程-Managed-Thread-vs-原生线程-Native-Threads"><a href="#托管线程-Managed-Thread-vs-原生线程-Native-Threads" class="headerlink" title="托管线程(Managed Thread) vs 原生线程(Native Threads)"></a>托管线程(Managed Thread) vs 原生线程(Native Threads)</h3><p>托管代码在“托管线程”上执行,“托管线程”与操作系统提供的原生线程不同,原生线程是在物理机上执行原生代码的线程.托管代码是在CLR虚拟机执 行的虚拟线程.</p><p>就像JIT编译器将“虚拟”IL指令映射到原生指令在物理机上执行一样,CLR的线程<strong>infrastructure</strong>将“虚拟”的托管线程映射到操作系统的原生线程上.</p><p>在任何时候,一个托管线程也许会,也可能不会分配一个原生线程来执行.例如一个已创建(通过“new System.Threading.Thread”)但是未启动(通过System.Threading.Thread.Start)的托管线程没有被分配任何的原生线程.同样,一个托管线程也可能在执行过程中在多个的原生线程之间移动,尽管实际上CLR目前不支持此操作.</p><p>托管代码可使用公共线程接口有意隐藏了关于底层中原生线程的细节,因为</p><ul><li>托管线程不一定会映射到单个原生线程(也可能根本没有映射到原生线程上)</li><li>不同到操作系统提供了不同的原生线程的抽象.</li><li>原则上,托管线程是“虚拟的”.</li></ul><p>CLR提供了托管线程的抽象.例如,未公开操作系统的线程本地存储(TLS)机制.而是提供了托管的“静态线程(thread-static)”变量.同样没有暴露原生线程的“线程ID”,而是提供了独立于OS的托管“线程ID”.出于诊断的目的,可以通过System.Diagnostics命名空间下的类型获取原生线程的一些底层细节.</p><p>托管线程需要一些原生线程通常不用的功能.首先,托管线程需将GC引用保存在栈上,以便CLR能够在每次发生GC时枚举(或修改)这些引用.为此,CLR需要“挂起(suspend)”所有托管线程(暂停在可以找到所有GC引用的点).第二,当AppDomain卸载时.CLR必须确保没有线程在该AppDomain中执行代码.这要求CLR能够让线程强制从该AppDomain中回退出来.CLR通过向这些线程注入ThreadAbortException来实现.</p><h3 id="数据结构-Data-Structures"><a href="#数据结构-Data-Structures" class="headerlink" title="数据结构(Data Structures)"></a>数据结构(Data Structures)</h3><p>每一个托管线程都有关联的Thread对象,定义在<a href="https://github.com/dotnet/coreclr/blob/master/src/vm/threads.h">threads.h</a>.该对象跟踪虚拟机需要的关于托管线程的一切信息,如当前GC模式与Frame chain的必要信息,以及处于性能原因分配到每个线程中的信息(例如arena-style allocators[1]).</p><p>所有的线程对象都存储在ThreadStore(同样定义在[threads.h]),包含了所有已知线程对象的简单列表.要枚举所有的托管线程,必须先获取ThreadStoreLock,然后使用ThreadStore::GetAllThreadList来枚举全部的线程对象.该列表可能包含未分配原生线程的托管线程(它们可能没有启动或原生线程已经退出).</p><p>所有被分配了托管线程的原生线程,都可以通过访问线程局部存储(TLS)来获取绑定的托管线程.这允许执行在原生线程的代码获取相应的线程对象,例如GetThread().</p><p><strong>Additionally, many managed threads have a managed Thread object (System.Threading.Thread) which is distinct from the native Thread object. The managed Thread object provides methods for managed code to interact with the thread, and is mostly a wrapper around functionality offered by the native Thread object. The current managed Thread object is reachable (from managed code) via Thread.CurrentThread.</strong>/此外,许多托管线程都有一个托管的线程对象(System.Threading.Thread),它与原生的线程对象不同.托管的线程对象提供了托管代码与线程进行交互的方法.主要是对原生线程对象提供的功能进行了封装.当前的托管线程对象可以通过(来自托管代码)Thread.CurrentThread拿到.</p><p>debugger时,可以使用SOS的拓展命令”!Thread”枚举出ThreadStore中的所有线程对象.</p><h3 id="线程生命周期-Thread-Lifetimes"><a href="#线程生命周期-Thread-Lifetimes" class="headerlink" title="线程生命周期(Thread Lifetimes)"></a>线程生命周期(Thread Lifetimes)</h3><p>一个托管线程将在以下场景被创建<br>    1. 托管代码通过System.Threading.Thread,明确要求CLR进行创建新线程.<br>    2. CLR直接创建托管线程(参见下面的[特殊线程][<a href="https://github.com/dotnet/coreclr/blob/master/Documentation/botr/threading.md#special-threads]">https://github.com/dotnet/coreclr/blob/master/Documentation/botr/threading.md#special-threads]</a>)<br>    3. 在原生线程上,由原生代码调用托管代码,而原生线程还没有与托管线程关联(通过”reverse p/invoke”或COM互操作).<br>    4. 托管进程启动(在进程的主线程上调用Main函数)</p><p>在#1,#2情况下,CLR负责创建一个原生线程来支持托管线程.这只会在线程被实际启动后完成.在这种情况下,CLR”持有”这个原生线程;CLR负责这个原生线程的生命周期.在这种情况下,<strong>~the CLR is aware of the existence of the thread by virtue of the fact that the CLR created it in the first place.</strong></p><p>在#3,#4的情况下,原生线程在托管线程被创建前就已经存在,并且由CLR的外部代码””.CLR不负责原生线程的生命周期.CLR在这些线程首次尝试调用托管代码时,才会意识到这些线程的存在.</p><p>当原生线程死亡时,CLR会通过DllMain方法接收到通知.这发生在OS的”loader lock”内部,在处理此通知时,几乎无法(安全)完成.因此与其销毁托管线程相关联的数据结构,不如将线程简单地标记成”dead”并向finalizer线程发送运行信号(signals).finalizer线程将遍历ThreadStore中的线程,并通过托管代码销毁已死且不可达的线程.</p><h3 id="挂起-Suspension"><a href="#挂起-Suspension" class="headerlink" title="挂起(Suspension)"></a>挂起(Suspension)</h3><p>CLR必须能够找到所有的托管对象的引用以便执行GC.托管代码不断访问GC堆,操作存储在栈与寄存器中的引用.CLR必须确保所有的托管线程都已经停止(所以他们不会修改堆),以便安全可靠的找到所有的托管对象.它将仅在安全点暂停,此时可以检查寄存器与栈空间的实时引用.</p><p>针对GC堆的另外一种说法:GC堆以及每个线程的栈和寄存器状态都是”共享状态(shared state)”,可以被多个线程访问.与大多数共享状态一样,需要某种锁来保护它.托管代码在访问堆时必须持有此锁,并且只能在安全点释放该锁.</p><p>CLR将此”锁”称为线程的”GC模式”,对于”Cooperatibe mode(合作模式)”的线程将持有此锁;它必须与GC合作(通过释放此锁)才能进行GC.处于”Preemptive(抢占模式)”的线程不需要持有锁-GC可以抢占的执行因为已知线程不会访问GC堆.</p><p>只有当所有的托管线程都处于”抢占模式(不持有锁)”GC才可以进行.将所有的托管线程移动至抢占模式的过程,称为”GC suspension-GC挂起”或”suspending the Execution Engine(EE)-挂起执行引擎”.</p><p>一个关于”锁”的天真方案,每个托管线程在访问GC堆前后都获取并释放锁,然后GC将简单的尝试获取每个线程的锁;一旦持有了全部线程的锁时,就可以安全的执行GC</p><p>然而,上述的方案存在两个缺陷,首先,托管代码会在持有跟释放锁上花费大量时间(或最小检查GC是否正在尝试持有锁.也叫GC轮询).其次,将要求JIT生成大量的”GC info”,描述每一行代码经过JIT后栈和寄存器的布局.</p><p>我们改进了上述方案,将JIT后的托管代码分成两类:”partially interruptible(部分可中断)”和”(fully interruptible)完全可中断”.在部分可中断的代码中,唯一安全点是调用其他方法,且JIT明确生成”GC轮询”点,以便检查是否有GC正在等待.JTI只需要在这些地方生成GC信息.在完全可中断的代码中,每条指令都是安全点,且JIT会为每条指令生成GC信息-但不会生成GC轮询的代码.与之相反,完全可中断的代码可能会通过”hijacking(劫持)”线程的方式来中断(这个过程将放到本文后面讨论).JIT基于启发式方法选择是否生成完全/部分可中断的代码.在代码质量,GC信息的大小与GC的挂起延迟之间找到最佳的权衡点.</p><p>综上所述,我们定义了三个阶段:进入抢占模式,离开抢占模式和挂起执行引擎(Execution Engine)</p><h3 id="进入合作模式-Entering-Cooperative-Mode"><a href="#进入合作模式-Entering-Cooperative-Mode" class="headerlink" title="进入合作模式(Entering Cooperative Mode)"></a>进入合作模式(Entering Cooperative Mode)</h3><p>当需要发生GC时,第一步是调用GCHeap::SuspendEE,挂起EE,具体操作如下:<br>    1. 设置一个全局flag(g_fTrapReturningThreads)标识GC正在进行中.任何尝试进入合作模式的线程都会阻塞,直到GC完成.<br>    2. 查找当前正处于合作模式的线程.尝试劫持线程,以迫使它离开合作模式.<br>    3. 重复上述步骤,直到没有现成处于合作模式.</p><h3 id="劫持-Hijacking"><a href="#劫持-Hijacking" class="headerlink" title="劫持(Hijacking)"></a>劫持(Hijacking)</h3><p>在GC的挂起过程中,劫持由Thread::SysSuspendForGC完成.该方法通过强制将当前正处于合作模式下的托管线程,在”安全点”离开合作模式.并通过枚举所有托管线程(通过访问ThreadStore),对当前正处于合作模式下的进行一下操作:<br>    1. 通过调用Win32 SuspendThread API,挂起底层的原生线程.强制线程从运行状态停止在任意状态(不一定是安全点).<br>    2. 通过 GetThreadContext获取当前线程上下文.这是OS的概念,上下文包含了线程当前的寄存器状态.以便我们检查它的指令指针寄存器(IP/IAR),从而确定当前正在执行的代码类型.<br>    3. 再次检查线程是否处于合作模式,因为它在被挂起前就已经离开了合作模式.If so,代码就正处于危险区域:线程也许正在执行任何的原生代码,必须立刻恢复以避免死锁.<br>    4. 检查线程是否在运行托管代码.可能正处与合作模式中执行原生VM代码(详见下文的Synchronization章节),这种情况也需如上一步,立即恢复线程.<br>    5. 现在,该线程已经在托管代码中被挂起.根据代码处与完全/部分可中断,执行以下操作之一:</p><ul><li><p>If fully interruptable, it is safe to perform a GC at any point, since the thread is, by definition, at a safe point. It is reasonable to leave the thread suspended at this point (because it’s safe) but various historical OS bugs prevent this from working, because the CONTEXT retrieved earlier may be corrupt). Instead, the thread’s instruction pointer is overwritten, redirecting it to a stub that will capture a more complete CONTEXT, leave cooperative mode, wait for the GC to complete, reenter cooperative mode, and restore the thread to its previous state.</p></li><li><p>If partially-interruptable, the thread is, by definition, not at a safe point. However, the caller will be at a safe point (method transition). Using that knowledge, the CLR “hijacks” the top-most stack frame’s return address (physically overwrite that location on the stack) with a stub similar to the one used for fully-interruptable code. When the method returns, it will no longer return to its actual caller, but rather to the stub (the method may also perform a GC poll, inserted by the JIT, before that point, which will cause it to leave cooperative mode and undo the hijack).</p></li></ul>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;原文信息&quot;&gt;&lt;a href=&quot;#原文信息&quot; class=&quot;headerlink&quot; title=&quot;原文信息&quot;&gt;&lt;/a&gt;原文信息&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;原文来自于CLR的概要设计系列中,线程篇&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;本文将会介绍一些关于&lt;code&gt;托管线程&lt;/code&gt; &lt;code&gt;原生线程&lt;/code&gt;,&lt;code&gt;线程生命周期&lt;/code&gt;,&lt;code&gt;线程数据结构&lt;/code&gt;等设计&lt;/strong&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/dotnet/coreclr/blob/master/Documentation/botr/threading.md&quot;&gt;原文:dotnet/coreclr&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="C#" scheme="http://murph.site/categories/C/"/>
    
    
    <category term="C#" scheme="http://murph.site/tags/C/"/>
    
    <category term="性能诊断" scheme="http://murph.site/tags/%E6%80%A7%E8%83%BD%E8%AF%8A%E6%96%AD/"/>
    
    <category term="线程" scheme="http://murph.site/tags/%E7%BA%BF%E7%A8%8B/"/>
    
    <category term="概要设计" scheme="http://murph.site/tags/%E6%A6%82%E8%A6%81%E8%AE%BE%E8%AE%A1/"/>
    
    <category term="CLR Thread" scheme="http://murph.site/tags/CLR-Thread/"/>
    
    <category term="Thread" scheme="http://murph.site/tags/Thread/"/>
    
  </entry>
  
  <entry>
    <title>诊断性能问题的工作流程(0)</title>
    <link href="http://murph.site/2020/11/07/diagnosingMemoryPerformance-part0/"/>
    <id>http://murph.site/2020/11/07/diagnosingMemoryPerformance-part0/</id>
    <published>2020-11-07T14:27:26.000Z</published>
    <updated>2021-09-26T06:48:27.286Z</updated>
    
    <content type="html"><![CDATA[<p>原文为Maoni发布在Microfost Blog中的,诊断性能问题的工作流程系列.<br>目前共更新三章.在本章中,Maoni介绍了一些关于GC设计与工具的使用,如果您已经具备了诊断性能问题的经验,可以直接跳过本章.</p><a id="more"></a><h2 id="原文信息"><a href="#原文信息" class="headerlink" title="原文信息"></a>原文信息</h2><p><a href="https://twitter.com/maoni0">@Maoni Stephens-Twitter</a><br><a href="https://github.com/Maoni0">@Maoni Stephens-Github</a></p><p><img src="/img/1587561145552-0d8a560c-3b7d-443a-badc-a98ddbb6e7bf.png" alt="authorize"></p><p>如果这篇文章可以帮到您，那么这将是我最大的荣幸，希望您点进原文，在文章下方留下善意的回复，您的支持将是这些可敬的社区磐石保持创作激情中最大的一部分:)</p><p><a href="https://devblogs.microsoft.com/dotnet/work-flow-of-diagnosing-memory-performance-issues-part-0">原文</a></p><p><strong>中文版本将不会以任何形式收费，版权属与原作者</strong></p><hr><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>我想描述一下我是怎样诊断内存中的性能问题,更确切的说是在进行此类诊断的各种工作流程中可通用的部分.诊断性能问题没有固定的步骤,可以采用很多方式,我将尝试一下分解成可用于进行各种诊断一些基本的模块.</p><p>这一部分是针对于初学者的,所以如果您已经进行了一段时间的内存中性能问题分析,您可以安全的跳过这一章节.</p><p>首先,在我们开始讨论实际的诊断部分之前,先让我们了解一些高级知识,帮您指明正确的方向.</p><h3 id="GC的一些高级知识"><a href="#GC的一些高级知识" class="headerlink" title="GC的一些高级知识"></a>GC的一些高级知识</h3><h4 id="1-时间点-vs-时间段"><a href="#1-时间点-vs-时间段" class="headerlink" title="1)时间点 vs 时间段"></a>1)时间点 vs 时间段</h4><p>了解性能问题往往不是点状,这一点非常重要.内存问题通常不会突然出现,可能需要一段时间才能积累到明显的程度.</p><p>让我们举一个简单的例子,对于一个非常简单的没有世代的GC,它只会紧凑的进行阻塞式GC.这种情况会一直存在.如果您的GC刚刚结束,堆当然处在最小的点.如果您碰巧在这个时间点进行测量,您会认为“太好了;我的堆很小”.但如果您恰好在进行下一次GC之前测量,则堆可能会大得多,并且您会有一些不同的看法.这只是针对于一个简单的GC.想象一下当您有一个世代GC或并发式GC时会发生些什么.</p><p>这就是为什么了解一下GC的历史是及其重要的,看看GC是如何作出决策,以及这些决策是如何导致目前的情况.</p><p>遗憾的是,很多内存工具或诊断方法,都没有将其考虑在内,它们进行内存诊断都方式是“让我来告诉您,您碰巧问到的那个时间点,堆上的情况”.这往往无济于事,有时候甚至会完全误导人们.浪费时间去追寻一个不存在的问题或在一个完全错误的问题上取得一些完全错误的进展.</p><p>并不是说此类工具一点用处都没有-当问题很简单时,它们可能会有所帮助.如果您有一个非常严重的的内存泄漏,并且已经持续了一段时间,而您使用一个工具来显示当前的堆(采取进程转储或使用sos,或者另外的一些堆转储的工具),可能确实会很明显的显示出泄漏的是什么.</p><h4 id="2-世代GC"><a href="#2-世代GC" class="headerlink" title="2)世代GC"></a>2)世代GC</h4><p>根据设计,具有世代的GC并不会每次触发时收集整个堆.尝试对年轻代GC频率要比对老年代GC高得多,因为对老年代GC的成本往往要高得多.对于并发式的老年代GC来说,STW的的中断时间不会很长,但仍然会需要花费机器周期来完成GC的工作.</p><p>这也使查看堆变得更加复杂,如果您刚完成一个老年代的GC,特别是刚经历过压缩的GC,您的堆显然会比在该GC被触发之前小的多.但如果您查看年轻代的GC,它们可能正在压缩,但是区别在于堆大小可能不会有太大变化,这是设计上所实现的.</p><h4 id="3-压缩-vs-回收"><a href="#3-压缩-vs-回收" class="headerlink" title="3)压缩 vs 回收"></a>3)压缩 vs 回收</h4><p>回收不应该过多的改变堆的大小.在我们的实现中,我们仍然会放弃堆末尾的空间,所以整体的堆大小可能会变小,但总的来说,您可以认为整体的堆大小并没有发生改变,但是为了容纳年轻代的堆分配(或者用户分配在零代/LOH的情况下),会建立起自由空间(free spaces).</p><p>因此,如果您看到对二代的两次gc,一次正在压缩另一次正在回收.那么可以预计,压缩阶段结束后,堆大小会缩小很多.回收阶段的碎片化程度则会很高(在设计中,这是我们设计中的自由列表(free list)).</p><h4 id="4-分配-vs-存活"><a href="#4-分配-vs-存活" class="headerlink" title="4)分配 vs 存活"></a>4)分配 vs 存活</h4><p>虽然很多内存工具都会报告分配情况,但是GC的成本不仅仅是来自分配.当然分配会触发GC,这无疑是成本.但当GC工作时,成本主要取决于存活.当然,您不能同时处于分配率和存活率都很高的情况,这样只会非常快的用光内存.</p><h4 id="5-“主线GC方案-vs-非主线”"><a href="#5-“主线GC方案-vs-非主线”" class="headerlink" title="5)“主线GC方案 vs 非主线”"></a>5)“主线GC方案 vs 非主线”</h4><p>如果您的程序仅仅是使用栈并且创建了一些要使用的对象,GC多年来一直在优化.基本上就是“扫描堆栈得到根对象然后在那里处理对象”.这就是许多GC论文都将其视为唯一的方案的主线GC方案.当然作为一个存在了几十年的商业产品,为了适应客户的各种需求,我们还有一些其他的东西,例如GC句柄和终结器.</p><p>有一个很重要的事情请您理解,虽然多年来我们对这些进行了优化,但我们都是基于“没有太多的这些东西”基础上进行的假设,这显然不会适用于每个人.所以如果您确实使用了很多这些东西,在诊断内存问题时值得一看.换句话说,如果您没有内存问题,则无需在意;但是如果您有(例如high % time in GC),它们是很好的怀疑对象.</p><p>所有的这些信息都表示为ETW事件或在Linux上的等效事件-这就是为什么我们多年来投资于分析跟踪的工具的原因.</p><h3 id="开始捕捉跟踪"><a href="#开始捕捉跟踪" class="headerlink" title="开始捕捉跟踪"></a>开始捕捉跟踪</h3><p>我通常会从两条跟踪开始.第一次是为了获取准确的GC时间:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">perfview /GCCollectOnly /nogui collect</span><br></pre></td></tr></table></figure><p>完成后,在PerfView的cmd窗口按s停止.</p><p>这应该运行足够长的时间,充分捕获GC活动,例如,如果您知道问题何时会发生,则应该涵盖导致问题发生的时间(不仅仅只有发生问题的时间).</p><p>如果您知道要运行多长时间,您可以这样做(实际上更常用) -</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">perfview /GCCollectOnly /nogui /MaxCollectSec:1800 collect</span><br></pre></td></tr></table></figure><p>将1800(半小时)替换成您需要的秒数</p><p>这会收集infomational级别的GC事件和足够的OS事件,以及解码后的进程名称.这个命令非常轻量,所以它可以一直保持运行.</p><p>请注意,我给出的所有PerfView命令都有<code>/nogui</code>.PerfView确实有一个用于事件收集的UI,可以让您选择需要捕获的事件.就我而言,我从没使用过它(除了在我刚使用PerfView时使用过几次).一部分原因是因为我更喜欢命令行;另一个(更重要的)原因是命令行具有更多的灵活性,对自动化很友好.</p><p>当您搜集到跟踪数据后,您可以使用PerfView打开它并查看GCStats视图,有些人倾向于在完成收集后将其发送给我,但我真的鼓励每个需要定期进行内存诊断的人学习阅读这个视图,它非常有用.尽管跟踪如此轻量,但仍旧给我们提供了大量的信息.并且就算不能让我们找到根本原因,也会指出取得更大进展的方向.我在<a href="https://devblogs.microsoft.com/dotnet/gc-etw-events-1/">这篇文章</a>及续篇描述了这些视图,在文章中都有链接.所以我在这里不打算展示更多的图片.您可以自己很轻易的打开这些视图.</p><p>通过此视图很容易发现的问题类型的例子 -</p><ul><li><p>非常高的“% Time paused for garbage collection(垃圾收集的中断时间百分比)”.除非您正在做一些基准测试,特别是在测试分配性能(类似非常多GC的基准测试),否则这个不指标不应该高于百分之几.如果您发现该指标已经很高了,那就需要调查了.下面是一些会显著导致这个百分比增加的情况.</p></li><li><p>个别GC的中断事件特别长.60s的GC很长吗?是的,肯定很长!通常来说不是由于GC的工作导致的.根据我的经验,这往往是由于某些因素干扰了GC线程的工作.</p></li><li><p>过多主动触发GC(当 <strong>主动触发的GC/触发GC的总数量</strong> 比例很高时),特别是对第二代主动触发的GC时.</p></li><li><p>过多的针对二代堆GC - 对二代堆进行GC成本是十分昂贵的,尤其是当您有一个大堆时.即便使用了BGC,大部分工作都是并发完成的.但它仍需要花费机器周期,因此,如果您其他的GC都是针对第二代,这通常是指出了一个问题,一种明显的情况是它们大部分的触发理由都是AllocLarge.同样,在某些情况下这不一定是问题,例如,如果您的堆大部分都是LOH,并且没有在容器中运行,这意味着LOH默认不会进行压缩,在这种情况下,二代堆GC只会回收并快速的退出.</p></li><li><p>长时间的挂起问题 - 挂起通常应该远远小于1ms,如果需要几毫秒-10s,那就是问题,如果需要花费上百毫秒,那毫无疑问是问题.</p></li><li><p>过多的固定句柄 - 一般情况下,少量的几个固定句柄是可以的,但如果您在短暂的GC中看到数百个,那就值得关注了;如果您看到几千个,通常,这是告诉您需要进行调查了.</p></li></ul><p>这些只是您第一眼就能看到的东西.如果您要进行更加深入的挖掘,还有很多事情要做.我们下次在讨论.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;原文为Maoni发布在Microfost Blog中的,诊断性能问题的工作流程系列.&lt;br&gt;目前共更新三章.在本章中,Maoni介绍了一些关于GC设计与工具的使用,如果您已经具备了诊断性能问题的经验,可以直接跳过本章.&lt;/p&gt;</summary>
    
    
    
    <category term="C#" scheme="http://murph.site/categories/C/"/>
    
    
    <category term="C#" scheme="http://murph.site/tags/C/"/>
    
    <category term="性能诊断" scheme="http://murph.site/tags/%E6%80%A7%E8%83%BD%E8%AF%8A%E6%96%AD/"/>
    
    <category term="Maoni" scheme="http://murph.site/tags/Maoni/"/>
    
    <category term="PerfView" scheme="http://murph.site/tags/PerfView/"/>
    
  </entry>
  
  <entry>
    <title>Go中的Context</title>
    <link href="http://murph.site/2020/09/22/context-in-golang/"/>
    <id>http://murph.site/2020/09/22/context-in-golang/</id>
    <published>2020-09-22T14:27:26.000Z</published>
    <updated>2021-09-26T06:48:27.286Z</updated>
    
    <content type="html"><![CDATA[<h3 id="原文信息"><a href="#原文信息" class="headerlink" title="原文信息"></a>原文信息</h3><p><a href="https://levelup.gitconnected.com/@ricardo.linck">@ricardo.linck</a><br><a href="https://levelup.gitconnected.com/context-in-golang-98908f042a57">原文:Context in Golang!</a></p><a id="more"></a><hr><p>Golang应用程序使用Contexts来进行控制与管理非常关健的应用可靠性,例如在<a href="https://levelup.gitconnected.com/goroutines-and-channels-concurrent-programming-in-go-9f9f8495c34d">concurrent programming</a>中的数据共享与取消.这听起来似乎很琐碎,但实际并非如此.在Golang中Contexts的入口点是<code>context</code>包.它非常有用,并且可能是整个语言功能最多的包之一.如果您还没有遇到任何有关上下文之类的东西,您大概很快就会遇到(或者您只是没有注意到它).上下文的用法非常广泛,以至于多数软件包都依赖它,并也假设您也会这样做.它绝对是Golang生态系统中的一个关键组件.</p><p>这里是<code>context</code>软件包的官方文档 <a href="https://golang.org/pkg/context/.%E5%AE%83%E7%9C%9F%E7%9A%84%E5%BE%88%E6%A3%92,%E5%B9%B6%E4%B8%94%E5%8C%85%E5%90%AB%E4%BA%86%E5%BE%88%E5%A4%9A%E4%BE%8B%E5%AD%90.%E4%B8%BA%E4%BA%86%E5%B0%9D%E8%AF%95%E6%8B%93%E5%B1%95%E5%AE%83%E4%BB%AC,%E6%9D%A5%E8%AE%A9%E6%88%91%E4%BB%AC%E7%9C%8B%E7%9C%8B%E6%88%91%E5%9C%A8%E7%9C%9F%E5%AE%9E%E5%9C%BA%E6%99%AF%E6%98%AF%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E7%9A%84">https://golang.org/pkg/context/.它真的很棒,并且包含了很多例子.为了尝试拓展它们,来让我们看看我在真实场景是如何使用的</a>.</p><h3 id="使用上下文来包含您的数据"><a href="#使用上下文来包含您的数据" class="headerlink" title="使用上下文来包含您的数据"></a>使用上下文来包含您的数据</h3><p>一个常见的使用上下文的用户之一是用于共享数据,或者使用请求作用域的值.当您有多个函数并且想在他们之间共享数据,您可以使用上下文.</p><p>最简单的方法是使用函数 context.WithValue.这个函数会根据父上下文创建一个新的上下文,并对您指定的Key添加一个值.您可以把内部实现看做是上下文的内部是一个map.</p><p>所以您可以添加或者使用Key来找回Values,这是非常强大的,因为它允许您在上下文内部存储任何类型的数据.</p><p>下面是一个用上下文添加和找回数据的例子.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">&quot;context&quot;</span></span><br><span class="line"><span class="string">&quot;fmt&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">ctx := context.Background()</span><br><span class="line">ctx = addValue(ctx)</span><br><span class="line">readValue(ctx)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">addValue</span><span class="params">(ctx context.Context)</span> <span class="title">context</span>.<span class="title">Context</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> context.WithValue(ctx, <span class="string">&quot;key&quot;</span>, <span class="string">&quot;test-value&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">readValue</span><span class="params">(ctx context.Context)</span></span> &#123;</span><br><span class="line">val := ctx.Value(<span class="string">&quot;key&quot;</span>)</span><br><span class="line">fmt.Println(val)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>在上下文中添加和找回值</p></blockquote><p>在Context包设计背后有一种重要的方面,任何操作都会返回一个新的context.Context结构.这意味着您需要记住运行时要用带的返回值,并尽可能的使用新的上下文覆盖旧上下文.</p><p>这是来自于不可更改性(immutability)的关键设计.如果您想了解更多的关于gokang中的不可更改性,您可以阅读我的<a href="https://levelup.gitconnected.com/immutability-in-golang-7a13199060bb">这篇文章</a></p><p>要创建一个带有取消功能的上下文,您只需要使用函数<code>context.WithCancel(ctx)</code>将您的上下文通过参数传递进去.这会返回一个新的上下文与一个取消函数.您只需要调用取消函数,就可以取消上下文.</p><p>下面这个例子来自于<a href="https://medium.com/swlh/hedged-requests-tackling-tail-latency-9cea0a05f577">对冲请求(Hedged Request)</a>实现的带有取消功能的上下文.来让我们快速的回顾一下<a href="https://medium.com/swlh/hedged-requests-tackling-tail-latency-9cea0a05f577">对冲请求(Hedged Request)</a>:我们对一个外部服务发起请求,如果在我们定义的时间没有返回,我们会发出第二个请求.当请求返回了,所有其他的请求都会被取消掉.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">&quot;context&quot;</span></span><br><span class="line"><span class="string">&quot;fmt&quot;</span></span><br><span class="line"><span class="string">&quot;io/ioutil&quot;</span></span><br><span class="line"><span class="string">&quot;net/http&quot;</span></span><br><span class="line">neturl <span class="string">&quot;net/url&quot;</span></span><br><span class="line"><span class="string">&quot;time&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">queryWithHedgedRequestsWithContext</span><span class="params">(urls []<span class="keyword">string</span>)</span> <span class="title">string</span></span> &#123;</span><br><span class="line">ch := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">string</span>, <span class="built_in">len</span>(urls))</span><br><span class="line">ctx, cancel := context.WithCancel(context.Background())</span><br><span class="line"><span class="keyword">defer</span> cancel()</span><br><span class="line"><span class="keyword">for</span> _, url := <span class="keyword">range</span> urls &#123;</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(u <span class="keyword">string</span>, c <span class="keyword">chan</span> <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line">c &lt;- executeQueryWithContext(u, ctx)</span><br><span class="line">&#125;(url, ch)</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> r := &lt;-ch:</span><br><span class="line">cancel()</span><br><span class="line"><span class="keyword">return</span> r</span><br><span class="line"><span class="keyword">case</span> &lt;-time.After(<span class="number">21</span> * time.Millisecond):</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> &lt;-ch</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">executeQueryWithContext</span><span class="params">(url <span class="keyword">string</span>, ctx context.Context)</span> <span class="title">string</span></span> &#123;</span><br><span class="line">start := time.Now()</span><br><span class="line">parsedURL, _ := neturl.Parse(url)</span><br><span class="line">req := &amp;http.Request&#123;URL: parsedURL&#125;</span><br><span class="line">req = req.WithContext(ctx)</span><br><span class="line"></span><br><span class="line">response, err := http.DefaultClient.Do(req)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">fmt.Println(err.Error())</span><br><span class="line"><span class="keyword">return</span> err.Error()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">defer</span> response.Body.Close()</span><br><span class="line">body, _ := ioutil.ReadAll(response.Body)</span><br><span class="line">fmt.Printf(<span class="string">&quot;Request time: %d ms from url%s\n&quot;</span>, time.Since(start).Nanoseconds()/time.Millisecond.Nanoseconds(), url)</span><br><span class="line"><span class="keyword">return</span> fmt.Sprintf(<span class="string">&quot;%s from %s&quot;</span>, body, url)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>每个请求都是在一个独立的go routine中触发的.这个上下文被传递给所有触发的请求.唯一的逻辑就是将上下文传播给Http client.以便当取消函数辈调用时,可以优雅的取消请求和底层连接.对于接受context.Context作为参数的函数来说,这是一个非常常见的模式,它们要么主动地对上下文采取行动(比如检查它们是否已经取消),要么将它们传递给处理它的底层函数(本例中是通过http.Request的Do函数接受上下文)</p><h3 id="超时上下文"><a href="#超时上下文" class="headerlink" title="超时上下文"></a>超时上下文</h3><p>在处理外部请求时,超时是一种非常常见的模式,类似通过Http或gRPC查询数据库或者从其他服务中获取数据.使用Context包处理这些产经非常简单.您所需要做的就是调用函数<code>context.WithTimeout(ctx,time)</code>,传递您的上下文与实际的超时时间,类似这样</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ctx, cancel := context.WithTimeout(context.Background(), <span class="number">100</span>*time.Millisecond)</span><br></pre></td></tr></table></figure><p>您仍然可以接受到取消函数,以防您想手动触发它.它的工作方式与普通的超时上下文相同.</p><blockquote><p>一个好做法是,使用defer调用取消函数,避免内存泄露</p></blockquote><p>这个例子的行为非常直接.如果超时了,上下文会被取消.在HTTP调用的情况下,它的工作原理与上面的例子基本相同</p><h3 id="gRPC"><a href="#gRPC" class="headerlink" title="gRPC"></a>gRPC</h3><p>Context是gRPC在golang的实现中的一个基本部分.它即用来共享数据(如何取消<a href="https://github.com/grpc/grpc-go/blob/master/Documentation/grpc-metadata.md">元数据</a>)也用来控制流量,类似于取消流或请求.这是我的两个例子,来自于<a href="https://github.com/RicardoLinck/grpc-go">GitHub存储库</a>.</p><h4 id="Metadata"><a href="#Metadata" class="headerlink" title="Metadata"></a>Metadata</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*server)</span> <span class="title">Sum</span><span class="params">(ctx context.Context, req *calculatorpb.SumRequest)</span> <span class="params">(*calculatorpb.SumResponse, error)</span></span> &#123;</span><br><span class="line">log.Printf(<span class="string">&quot;Sum rpc invoked with req: %v\n&quot;</span>, req)</span><br><span class="line">md, _ := metadata.FromIncomingContext(ctx)</span><br><span class="line">log.Printf(<span class="string">&quot;Metadata received: %v&quot;</span>, md)</span><br><span class="line"><span class="keyword">return</span> &amp;calculatorpb.SumResponse&#123;</span><br><span class="line">Result: req.NumA + req.NumB,</span><br><span class="line">&#125;, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>Server implementation receiving metadata</p></blockquote><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">sum</span><span class="params">(c calculatorpb.CalculatorServiceClient)</span></span> &#123;</span><br><span class="line">req := &amp;calculatorpb.SumRequest&#123;</span><br><span class="line">NumA: <span class="number">3</span>,</span><br><span class="line">NumB: <span class="number">10</span>,</span><br><span class="line">&#125;</span><br><span class="line">ctx := metadata.AppendToOutgoingContext(context.Background(), <span class="string">&quot;user&quot;</span>, <span class="string">&quot;test&quot;</span>)</span><br><span class="line">res, err := c.Sum(ctx, req)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Fatalf(<span class="string">&quot;Error calling Sum RPC: %v&quot;</span>, err)</span><br><span class="line">&#125;</span><br><span class="line">log.Printf(<span class="string">&quot;Response: %d\n&quot;</span>, res.Result)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>Client implementation sending metadata</p></blockquote><h4 id="Calcellation"><a href="#Calcellation" class="headerlink" title="Calcellation:"></a>Calcellation:</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*server)</span> <span class="title">Greet</span><span class="params">(ctx context.Context, req *greetpb.GreetRequest)</span> <span class="params">(*greetpb.GreetResponse, error)</span></span> &#123;</span><br><span class="line">log.Println(<span class="string">&quot;Greet rpc invoked!&quot;</span>)</span><br><span class="line"></span><br><span class="line">time.Sleep(<span class="number">500</span> * time.Millisecond)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> ctx.Err() == context.Canceled &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, status.Error(codes.Canceled, <span class="string">&quot;Client cancelled the request&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">first := req.Greeting.FirstName</span><br><span class="line"><span class="keyword">return</span> &amp;greetpb.GreetResponse&#123;</span><br><span class="line">Result: fmt.Sprintf(<span class="string">&quot;Hello %s&quot;</span>, first),</span><br><span class="line">&#125;, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>Server implementation handling context cancellation</p></blockquote><pre><code class="go">func greetWithTimeout(c greetpb.GreetServiceClient) &#123;    req := &amp;greetpb.GreetRequest&#123;        Greeting: &amp;greetpb.Greeting&#123;            FirstName: &quot;Ricardo&quot;,            LastName:  &quot;Linck&quot;,        &#125;,    &#125;    ctx, cancel := context.WithTimeout(context.Background(), 100*time.Millisecond)    defer cancel()    res, err := c.Greet(ctx, req)    if err != nil &#123;        grpcErr, ok := status.FromError(err)        if ok &#123;            if grpcErr.Code() == codes.DeadlineExceeded &#123;                log.Fatal(&quot;Deadline Exceeded&quot;)            &#125;        &#125;        log.Fatalf(&quot;Error calling Greet RPC: %v&quot;, err)    &#125;    log.Printf(&quot;Response: %s\n&quot;, res.Result)&#125;</code></pre><h3 id="OpenTelemetry"><a href="#OpenTelemetry" class="headerlink" title="OpenTelemetry"></a>OpenTelemetry</h3><p><code>OpenTelemetry </code>还严重依赖于上下文来实现所谓的<strong>上下文传播(Context Propagation)</strong>.这是一种将不同系统中请求捆绑起来的做法.实现方式是将Span信息<code>注入(Inject)</code>到上下文中,作为您使用的协议的一部分(例如HTTP或gRPC).在另一个服务上,您需要<code>提取(Extrace)</code>Span信息.我在两篇文章中写过关于OpenTelemetry的文章,您可以在之类找到<a href="https://medium.com/swlh/distributed-tracing-with-opentelemetry-part-1-6719df95a364">part 1</a>,<a href="https://levelup.gitconnected.com/distributed-tracing-with-opentelemetry-part-2-cc5a9a8aa88c">part 2</a>.在这里您可以找到更多的关于OpenTelemetry的信息,以及使用gRPC和HTTP的例子.</p><h3 id="最后的一些想法"><a href="#最后的一些想法" class="headerlink" title="最后的一些想法"></a>最后的一些想法</h3><p>上下文是作为Golang基本特性的一部分.因此理解并知道如何使用它们是非常重要的.<code>Context</code>包提供了一个非常简单和轻量级的API来与这个关键组件进行交互.关于<code>context.Context</code>的另一个重要的事情是,它可以用于多种事情.我们再这篇文章中涉及到了很多场景,在其中一些场景中,一个单一的上下文可以用来控制和携带范围值.这使得上下文成为创建可靠和简单代码的一个非常重要和强大的工具.</p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;原文信息&quot;&gt;&lt;a href=&quot;#原文信息&quot; class=&quot;headerlink&quot; title=&quot;原文信息&quot;&gt;&lt;/a&gt;原文信息&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;https://levelup.gitconnected.com/@ricardo.linck&quot;&gt;@ricardo.linck&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://levelup.gitconnected.com/context-in-golang-98908f042a57&quot;&gt;原文:Context in Golang!&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Go" scheme="http://murph.site/categories/Go/"/>
    
    
    <category term="Go" scheme="http://murph.site/tags/Go/"/>
    
    <category term="Context" scheme="http://murph.site/tags/Context/"/>
    
    <category term="上下文" scheme="http://murph.site/tags/%E4%B8%8A%E4%B8%8B%E6%96%87/"/>
    
    <category term="架构设计" scheme="http://murph.site/tags/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>诊断性能问题的工作流程(2)</title>
    <link href="http://murph.site/2020/05/07/diagnosingMemoryPerformance-part2/"/>
    <id>http://murph.site/2020/05/07/diagnosingMemoryPerformance-part2/</id>
    <published>2020-05-07T14:27:26.000Z</published>
    <updated>2021-09-26T06:48:27.286Z</updated>
    
    <content type="html"><![CDATA[<p>原文为Maoni发布在Microfost Blog中的,诊断性能问题的工作流程系列.<br>目前共更新三章.在本章中,Maoni继续介绍了如何进行诊断性能问题,以及一个略微棘手的问题.</p><a id="more"></a><h2 id="原文信息"><a href="#原文信息" class="headerlink" title="原文信息"></a>原文信息</h2><p><a href="https://twitter.com/maoni0">@Maoni Stephens-Twitter</a><br><a href="https://github.com/Maoni0">@Maoni Stephens-Github</a></p><p><img src="/img/1587561145552-0d8a560c-3b7d-443a-badc-a98ddbb6e7bf.png" alt="authorize"></p><p>如果这篇文章可以帮到您，那么这将是我最大的荣幸，希望您点进原文，在文章下方留下善意的回复，您的支持将是这些可敬的社区磐石保持创作激情中最大的一部分:)</p><p><a href="https://devblogs.microsoft.com/dotnet/work-flow-of-diagnosing-memory-performance-issues-part-2">原文</a></p><p><strong>中文版本将不会以任何形式收费，版权属与原作者</strong></p><hr><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>在这一章中,我将讨论一下您应该将精力花费在哪里,然后继续我的分析.原本我打算深入研究GCStats视图,但我刚刚调试了一个长时间挂起的问题.我想分享给大家,当您在分析问题时,其中的一些通用的思路.当然,您也可以直接<a href="https://devblogs.microsoft.com/dotnet/work-flow-of-diagnosing-memory-performance-issues-part-2/#continuing-the-analysis">跳到分析部分</a>.</p><h3 id="请明智的花费精力"><a href="#请明智的花费精力" class="headerlink" title="请明智的花费精力"></a>请明智的花费精力</h3><p>PerfView不仅仅是用于收集痕迹的,更重要的是,它是用于分析痕迹的.我遇到过很多人,他们仅仅使用Perfview进行收集痕迹.我真的强烈鼓励您将其作为一个分析工具来使用.</p><p>PerfView中内置了大量的帮助,显然,我写这个系列的博客主要原因也是为了帮助您,只是更侧重内存方面.我这样做的最终目的-是帮助您<br>获得一些搞清楚性能问题的思路跟方法,而不是详细的列出您可能碰到的所有问题,这完全不现实.</p><p>我的理念是您应该明智的花费自己的时间,我都非常忙,有做不完的任务.我也明白,我中的许多人的性格都很独立,喜欢自己想办法.</p><p>所以,在请别人帮忙之前,您会自己完成多少工作呢?这是我遵循的几个规则 -</p><ul><li><p>慷慨的花时间去学习以后会经常用到的知识与技能,如果我正在研究一个以后不大可能再研究的领域中的问题,我倾向于尽早的寻求帮助,因为我知道在这里获得的知识可能只会用到一次.但如果我知道我需要再次解决这个领域的问题,我会花费尽可能多的时间来了解它.</p></li><li><p>如果我有一个紧急的问题,而我认识的人多半已经知道答案,我会尽早的向他们寻求帮助.而如果是我认为这是我需要知道的事情,我会先把问题处理好,然后花费时间去了解更多的细节(其他团队可能正在等待解决方案).当我真的向对方请求帮助时,我会提供问题的详细描述与调试的信息给对方,以节省对方询问的时间.</p></li></ul><h3 id="继续分析"><a href="#继续分析" class="headerlink" title="继续分析"></a>继续分析</h3><p>在<a href="https://devblogs.microsoft.com/dotnet/work-flow-of-diagnosing-memory-performance-issues-part-0/">Part0</a>我提到了我会从两个跟踪来开始调查.第二个跟踪是获取CPU采样和一些其他的通用事件,比如磁盘/网络IO :</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PerfView /nogui /accepteula /KernelEvents=default+Memory+VirtualAlloc /ClrEvents:GC+Stack /MaxCollectSec:600 /BufferSize:3000 /CircularMB:3000 collect</span><br></pre></td></tr></table></figure><p>第一个跟踪,也就是GCCollectOnly跟踪,是为了准确的了解GC的性能–您想在最小的干扰下进行收集,而命令行的参数GCCollectOnly正是做这个的.</p><p>第二个跟踪可以让您了解机器上的运行情况.GC生活在一个进程中的线程中,其他进程可能会影响GC的运行.请注意,目前在dotnet-trace中还没有等效的功能 - 您需要在Linux上使用<a href="https://github.com/dotnet/coreclr/blob/master/Documentation/project-docs/linux-performance-tracing.md#preparing-your-machine">perfcollect脚本</a>收集跟踪,例如perf+Lttng,不幸的是它不能提供完全等同的功能(Lttng没有栈)但是在其他方面,它确实能提供机器范围的视图,而不是像dotnet-trace只提供一个进程的事件.</p><p>请注意,我也指定了 <strong><code>/BufferSize:3000 /CircularMB:3000</code></strong> 参数,我现在收集的事件比较多,默认值可能不够用,对于GCCollectOnly,我知道它收集的事件不多,所以默认值就足够了.一般来说,我发现3000MB对于这个跟踪的两个参数都是足够的.如果这些大小有问题,PerfView会给出非常有参考价值的信息,所以请注意它弹出的对话框! 这是由HandleLostEvents方法触发的:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">HandleLostEvents</span><span class="params">(Window parentWindow, bool truncated, <span class="keyword">int</span> numberOfLostEvents, </span></span></span><br><span class="line"><span class="function"><span class="params">                            <span class="keyword">int</span> eventCountAtTrucation, StatusBar worker)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    string warning;</span><br><span class="line">    <span class="keyword">if</span> (!truncated)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// TODO see if we can get the buffer size out of the ETL file to give a good number in the message. </span></span><br><span class="line">        warning = <span class="string">&quot;WARNING: There were &quot;</span> + numberOfLostEvents + <span class="string">&quot; lost events in the trace.\r\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;Some analysis might be invalid.\r\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;Use /InMemoryCircularBuffer or /BufferSize:1024 to avoid this in future traces.&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        warning = <span class="string">&quot;WARNING: The ETLX file was truncated at &quot;</span> + eventCountAtTrucation + <span class="string">&quot; events.\r\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;This is to keep the ETLX file size under 4GB, however all rundown events are processed.\r\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;Use /SkipMSec:XXX after clearing the cache (File-&gt;Clear Temp Files) to see the later parts of the file.\r\n&quot;</span> +</span><br><span class="line">            <span class="string">&quot;See log for more details.&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong><code>If</code></strong> 的情况是告诉您有事件丢失了,您同时记录了太多的事件,而缓冲区不够大.所以它告诉您,应该通过 <strong><code>/BuffSize</code></strong> 指定一个更大的值.我一般觉得 <strong><code>/InMemoryCircularBuffer</code></strong> 参数不可靠,所以我一般不用它.</p><p><strong><code>Else</code></strong> 的情况是告诉您,您使用的 <strong><code>/CircularMB</code></strong> 参数太大了,导致PerfView生成的.etlx文件太大,不能一次解析完,所以当您使用PerfView查看跟踪时,它将只显示可以容纳在4GB.etlx中第一部分的信息.这并不意味着您需要减少这个参数的大小,这只是意味着您需要采取额外的步骤才能看到所有信息.要看到后面的部分,您需要跳过第一部分,这正是对话框中告诉您需要做的.通常您会看到这个对话框与第二个跟踪.</p><p>我的做法是,查看GCStats找出哪个时间段是我感兴趣的,然后跳过之前的部分.请注意,如果您看我在<a href="https://devblogs.microsoft.com/dotnet/gc-perf-infrastructure-part-1/">这篇博客</a>提到的GC性能基础结构的跟踪,您就不会有这个问题,因为基础结构会查看.etl文件,不会经过.etlx的步骤.这就解释了为什么当您使用GC Perf infra时,您可以看到比您在PerfView中更多的GC</p><p>指定 <strong><code>/ClrEvents:GC+Stack</code></strong> 参数是很重要的,运行时的默认会收集大量的关键词–</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Default &#x3D; GC | Type | GCHeapSurvivalAndMovement | Binder | Loader | Jit | NGen | SupressNGen | StopEnumeration | Security | AppDomainResourceManagement | Exception | Threading | Contention | Stack | JittedMethodILToNativeMap | ThreadTransfer | GCHeapAndTypeNames | Codesymbols | Compilation,</span><br></pre></td></tr></table></figure><ul><li>Default = GC</li><li>Type</li><li>GCHeapSurvivalAndMovement</li><li>Binder</li><li>Loader</li><li>JIt</li><li>NGen</li><li>SupressNGen</li><li>StopEnumeration</li><li>Security</li><li>AppDomainResourceManagement</li><li>Exception</li><li>Threading</li><li>Contention</li><li>Stack</li><li>JittedMethodILToNativeMap</li><li>ThreadTransfer</li><li>GCHeapAndTypeNames</li><li>Codesymbols</li><li>Compilation</li></ul><p>其中一些会人为的增大很多GC的暂停时间.比如 <strong><code>GCHeapSurvivalAndMovement</code></strong>,它实际上向BGC添加了另一个STW暂停,可能会使BGC的实际STW暂停时间增加十倍以上.</p><p>当我知道自己要专注于GC的性能时,我会选择不收集rundown事件,即在命令行中添加 <strong><code>/NoV2Rundown /NoNGENRundown /NoRundown</code></strong> 这意味着我不会得到一些托管的调用帧(ie, moduleA!? instead of something like <strong><code>moduleX!methodFoo(argType)</code></strong> ).但如果您作为一个使用GC的客户,rundown事件是非常有用的,您可以得到来自于您代码的托管调用帧,来验证是否可以通过修改代码来帮助改善性能.</p><p>性能问题的类别之一是偶尔的长时间GC(您可以很容易的在GCCollectOnly的跟踪中发现他们),您可以使用这个命令行,让PerfView在观察到长GC时立刻停止跟踪:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PerfView.exe &#x2F;nogui &#x2F;accepteula &#x2F;StopOnGCOverMSec:100 &#x2F;Process:MyProcess &#x2F;DelayAfterTriggerSec:0 &#x2F;CollectMultiple:3 &#x2F;KernelEvents&#x3D;default+Memory+VirtualAlloc &#x2F;ClrEvents:GC+Stack &#x2F;BufferSize:3000 &#x2F;CircularMB:3000 collect</span><br></pre></td></tr></table></figure><p>用您的进程名字替换掉MyProcess(如果您的进程名字是a.exe,这里的参数不含.exe,应该是/Process:A)</p><p>用一个恰当的数字替换掉100(如果您想捕获一个500ms的GC,就用500替换).</p><p>我在<a href="https://devblogs.microsoft.com/dotnet/you-should-never-see-this-callstack-in-production/">这篇博客</a>中解释了很多这样的参数,所以在这里就不在赘述了.</p><p>这个停止触发器(在本例中是 <strong><code>/StopOnGCOverMSec</code></strong>)是我在PerfView中最喜欢的功能之一.dotnet-trace暂时还没有这个功能(没有不提供的理由,这是需要处理的工作之一).我通常会从这里开始,尤其是当长GC已经相当可观时.他的开销确实比/GCCollectOnly的大得多,但不会太大(通常是个位数的百分比).所以我预测产品仍然可以正常的运行,并且一直重现同样的问题.我见过人们追逐由<code>Heisenberg effect(海森堡效应)</code>引发的不同性能问题.</p><p>还有其他的停止触发器.要获得有关于它们的帮助,点击Help/Command Line Helper,然后在帮助页面上搜索StopOn.你会看到一堆与各种触发条件有关的停止跟踪开关.与GC相关的有:</p><ul><li>[-StopOnPerfCounter:STRING,…]</li><li>[-StopOnEtwEvent:STRING,…]</li><li>[-StopOnGCOverMsec:0]</li><li>[-StopOnGCSuspendOverMSec:0]</li><li>[-StopOnBGCFinalPauseOverMsec:0]</li></ul><p>前两个是通用的,所以可以使用在任何的性能计数器/ETW事件上.我自己从没有手动的使用过-StopOnEtwEvent触发器.我觉得这个参数很有潜力,只是我还没有时间去实验它.</p><p>最后三个不需要我解释. <strong><code>StopOnGCOverMSec</code></strong> 是最常用的一个.请注意,<strong><code>StopOnGCOverMSec</code></strong> 指的是GC/Start与GC/Stop的间隔时间,如果您指定了/StopOnGCMSec:500,意味着一旦检测到GC/Start与GC/Stop的间隔超过了500ms,跟踪就会停止.如果您正在观察长时间的挂起,您需要使用 <strong><code>StopOnGCSuspendOverMSec</code></strong> 触发器,它实际上在内部与StopOnEtwEvent一起实现,比较 <strong><code>SuspendEEStart</code></strong> 和 <strong><code>SuspendEEStop</code></strong> 时间的间隔触发 - </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">etwStopEvents.Add(&quot;E13C0D23-CCBC-4E12-931B-D9CC2EEE27E4&#x2F;GC&#x2F;SuspendEEStart;StopEvent&#x3D;GC&#x2F;SuspendEEStop;StartStopID&#x3D;ThreadID;Keywords&#x3D;0x1;TriggerMSec&#x3D;&quot; + StopOnGCSuspendOverMSec);</span><br></pre></td></tr></table></figure><h4 id="长时间挂起"><a href="#长时间挂起" class="headerlink" title="长时间挂起"></a>长时间挂起</h4><p>现在来说说我刚调试的客户问题-从来自GCCollectOnly的跟踪中,我看到一些GC花费了很长的时间在挂起上(3/4秒!).我还让他们收集了第二个跟踪,并查看发生长时间挂起期间的CPU采样.请注意,出现这种情况时,只有挂起的时间很长,GC部分是正常的.还有一种特殊情况是,挂起与GC的时间都是随机长的,或其中一个很长.通常这种情况是有什么东西阻碍了GC线程的运行.最常见的原因是机器上有一个优先级很高的线程(通常是意外的)在运行时会出现这种情况.</p><p>在这种情况下,我已经验证了这个问题总是在挂起时才会表现出来.而从第二个跟踪中,我可以看到一些IO正在进行,我知道这可能就是阻止挂起的原因.然而,这只是基于我所掌握的知识,如果我不知道,我可以做些什么来验证这个理论?另外,我想展示给我的客户,到底是如何阻止挂起的.这个时候就需要一个更加重量级的跟踪,即 <strong><code>ThreadTime</code></strong> 跟踪.如果您有一个线程没有完成它的工作,要么这个工作就是需要很长时间,要么就是有什么东西导致它长时间的阻塞.如果它被阻塞了,在某些时候它会被唤醒,我想知道是谁唤醒了它.收集Context Switch(上下文切换)与ReadyThread(准备线程)事件正是做这个的–看看一个线程为什么会被切换,以及谁来启用并再次执行它.在PerfView中叫做 <strong><code>ThreadTime</code></strong> 跟踪.它仅收集默认的kernel事件加上这两个事件.所以您可以把 <strong><code>/KernelEvents=default+Memory+VirtualAlloc</code></strong> 替换成 <strong><code>/KernelEvents=ThreadTime+Memory+VirtualAlloc</code></strong> .这些Context Switch和Ready Thread事件会非常多,所以有时候原来的问题长时间都不能复现,在这种情况下,问题会复现的.</p><p>请查看PerfView的帮助来获得更多使用 <strong>ThreadTime</strong>跟踪的说明.</p><p>当您有Ready Thread事件时,PerfView中的”Advanced Group(高级组)”下方会额外多出一个视图,叫做”ThreadTime(with ReadyThread) stacks - 线程时间(含准备线程))栈”. 我通常要做的就是打开这个视图,搜索阻塞的时间段内被阻塞的调用,并查看它的”READIED_BY”调用栈,导致哪些线程被唤醒.所以我做的是384,026.930 到 387,822.395的这个时间段,也就是GCStats标识的挂起事件,复制到这个视图中的Start和End框中,然后在Find框中搜索suspend,并点击Callees.这就是我所看到的- </p><p><img src="/img/WorkFlow-suspension-readythread-view.jpg" alt="WorkFlow-suspension-readythread-view"></p><p>我希望看到一个READIED_BY的栈,它唤醒并调用SuspendEE线程,确实有一个,但是没有用,因为它展示的调用栈不够深,引发问题的我的代码或者客户代码的一些东西.它仍然在ntoskrnl中(Windows系统内核).</p><p>所以对于这种情况,我可以请PerfView的owner来看看(当时已经是深夜了;即便他当时真的响应了,也未必有时间马上来看,而且这个看起来也不是什么可以马上解决的小事.我真的很想把这个问题搞清楚😀),或者我可以自己想一些其他的办法来取得更多的进展.当针对一类问题设计的视图不能使用时,总会有一个视图可以拯救您,那就是事件视图.当然,可能还有其他工具可以解决它们,比如WPA.但我上一次认真使用WPA已经是好几年的前的事了,UI和我熟悉的UI已经有很大的不同.</p><p>事件视图是事件的原始版本,包含在.etl文件中(这并不完全准确,PerfView仍然对一些事件进行了处理;但在多数情况下,它是非常原始的–您可以得到事件的名称和每个事件的字段).而我最感兴趣的ReadyThread事件,他告诉我哪个线程是由其他的哪个线程唤醒的.所以我做的第一件事就是过滤到我想看到的事件.否则会有太多的事件.我打开”Event”视图,再次输入开始和结束的时间戳,就像我在其他视图中做的那样,然后在Process Filter中输入感兴趣的过程(为了保护隐私,我仅仅使用X来说明).为了只过滤挂起和ReadyThread事件,我在filter框中输入sus|ready.这将只包含”sus”或”ready”的事件 –</p><p><img src="/img/WorkFlow-suspension0.jpg" alt="WorkFlow-suspension0"></p><p>现在,选中三个事件并输入回车,现在我只会看到这三个-</p><p><img src="/img/WorkFlow-suspension1.jpg" alt="WorkFlow-suspension1"></p><p>这里有很多事件,但我只对那些唤醒我的线程感兴趣,也就是本例中的GC线程<code>ThreadID 7736</code>(在服务器GC中,SuspendEE总是由Heap0的GC线程调用),手动检查这些线程是很困难的,所以我希望只过滤那些有趣的线程.做到这一点的方法是让事件视图展示一列单独的字段,这样我就可以进行排序–在默认情况下,它只在一列中显示所有字段.我可以通过点击Cols按钮(“Columns To Display”旁边),选择我想要显示的字段.我选择了三个字段,分别是–</p><p><img src="/img/WorkFlow-suspension2.jpg" alt="WorkFlow-suspension2"></p><p>现在,它显示了这三个字段,然后我按AwakenedThreadID进行排序,并寻找我的线程7736.</p><p><img src="/img/WorkFlow-suspension3.jpg" alt="WorkFlow-suspension3"></p><p>果然,有一个有意思的线程-线程33108.如果我点击其中一个时间戳,然后按Alt+S(意味着打开与这个时间戳相关的任意调用栈;您也可以通过上下文的菜单进入),我看到了这个调用栈–</p><p><img src="/img/WorkFlow-suspension4.jpg" alt="WorkFlow-suspension4"></p><p>底部写着”Readied Thread 7736”.而其他的时间戳几乎都有相同的调用栈.我只显示了运行时里面的部分,但是对于客户代码里面的部分,总是同一个dll抛出的异常.原来这是我挂起代码的一个BUG-它在调用 <strong><code>GetFileVersionInfoSize</code></strong> 系统API之前,应该先切换到抢占模式.我猜测这是一个处理异常的代码地址(最上面的异常处理代码叫做 <strong><code>coreclr!DwGetFileVersionInfo</code></strong> ),它没有被广泛使用,所以我直到现在才注意到.对客户来说,一个变通的方法是避免让他们的dll抛出这些异常,这样会使它不调用这个运行时的代码地址.</p><p>这就是今天的全部内容了,如果您有任何反馈,请一如既往的告诉我.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;原文为Maoni发布在Microfost Blog中的,诊断性能问题的工作流程系列.&lt;br&gt;目前共更新三章.在本章中,Maoni继续介绍了如何进行诊断性能问题,以及一个略微棘手的问题.&lt;/p&gt;</summary>
    
    
    
    <category term="C#" scheme="http://murph.site/categories/C/"/>
    
    
    <category term="C#" scheme="http://murph.site/tags/C/"/>
    
    <category term="性能诊断" scheme="http://murph.site/tags/%E6%80%A7%E8%83%BD%E8%AF%8A%E6%96%AD/"/>
    
    <category term="Maoni" scheme="http://murph.site/tags/Maoni/"/>
    
    <category term="PerfView" scheme="http://murph.site/tags/PerfView/"/>
    
  </entry>
  
  <entry>
    <title>诊断性能问题的工作流程(1)</title>
    <link href="http://murph.site/2020/05/06/diagnosingMemoryPerformance-part1/"/>
    <id>http://murph.site/2020/05/06/diagnosingMemoryPerformance-part1/</id>
    <published>2020-05-06T14:27:26.000Z</published>
    <updated>2021-09-26T06:48:27.286Z</updated>
    
    <content type="html"><![CDATA[<p>原文为Maoni发布在Microfost Blog中的,诊断性能问题的工作流程系列.<br>目前共更新三章.在本章中,Maoni介绍了一些在进行性能诊断时的操作与分析.</p><a id="more"></a><h2 id="原文信息"><a href="#原文信息" class="headerlink" title="原文信息"></a>原文信息</h2><p><a href="https://twitter.com/maoni0">@Maoni Stephens-Twitter</a><br><a href="https://github.com/Maoni0">@Maoni Stephens-Github</a></p><p><img src="/img/1587561145552-0d8a560c-3b7d-443a-badc-a98ddbb6e7bf.png" alt="authorize"></p><p>如果这篇文章可以帮到您，那么这将是我最大的荣幸，希望您点进原文，在文章下方留下善意的回复，您的支持将是这些可敬的社区磐石保持创作激情中最大的一部分:)</p><p><a href="https://devblogs.microsoft.com/dotnet/work-flow-of-diagnosing-memory-performance-issues-part-1">原文</a></p><p><strong>中文版本将不会以任何形式收费，版权属与原作者</strong></p><hr><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>在此篇文章中,我会讨论一些关于怎样对PerfView做出贡献的内容,然后继续分析GCStats.您可以直接<a href="https://devblogs.microsoft.com/dotnet/work-flow-of-diagnosing-memory-performance-issues-part-1/#continuing-the-analysis">跳到分析部分</a>.</p><p>对于分析工具,有一点令我沮丧,市面上有很多的内存性能工具,但很少有针对可通用类型以及与我所服务的客户的.所有的工具都很基础,很少有工具能进行中级和高级分析.</p><p>我知道有很多人在抱怨PerfView的可用性 - 我确实赞同一些抱怨.但尽管如此,我还是喜欢PerfView,因为这是它往往是我唯一一个能用来完成工作的工具.</p><p>我希望大家能够理解</p><ol><li>我能放在PerfView上的精力非常有限.我没有类似Visual Studio组织完整的工作团队;我只有部分时间,来自于少部分成员的兼职,所以很难满足所有用户的要求.</li><li>在进行高级分析时,情况会变得非常复杂,这意味着实现可用性没有那么简单-当有很多需要关注的细节时,permutation很快会变得十分庞大.</li></ol><p>对类似PerfView之类的项目做出贡献,是对<code>.NET Core</code>做出贡献的绝佳方式,它没有运行时本身那么陡峭的学习曲线,但是您的贡献可能会帮助人们节省大量时间. </p><p>您可以从克隆<a href="https://github.com/microsoft/perfview/">Perfview repo</a>并编译它开始.然后您可以通过单步执行代码来学习了 – IMO 单步执行代码, 这往往是最好的了解新鲜事物的方法.</p><p>我在此讨论内容的代码大部分都位于2个文件中</p><pre><code>- src\TraceEvent\Computers\TraceManagedProcess.cs - src\PerfView\GCStats.cs. </code></pre><p>如果您搜索诸如Clr.EventName(例如Clr.GCStart与Clr.GCStop),这里就是进行事件分析的地方(您不需要关心对于跟踪的解析 – 那在其他地方处理的).</p><p>对于GC的分析就是这个文件中的<a href="https://devblogs.microsoft.com/dotnet/glad-part-2/">GLAD</a> (GC Latency Analysis and Diagnostics)库.GCStats.cs使用它来显示您在GCStats视图中看到的东西,它是一个HTML文件.如果您想在自己的工具上展示GC的相关信息,GCStats.cs是一个很好的使用GLAD的例子.</p><h3 id="继续分析"><a href="#继续分析" class="headerlink" title="继续分析"></a>继续分析</h3><p>在上一篇文章,我讨论了关于收集GCCollectOnly的跟踪,并在PerfView中启用GC事件集合以及检查GCStats视图.</p><p>我应该提醒您,在Linux上可以使用dotnet-trace来做这件事. 根据<a href="https://github.com/dotnet/diagnostics/blob/master/documentation/dotnet-trace-instructions.md">dotnet-trace的文档</a>:它提供了一个内置配置,与<code>/GCCollectOnly</code>参数等效的收集命令.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--profile</span><br><span class="line"></span><br><span class="line">  [omitted]</span><br><span class="line"></span><br><span class="line">  gc-collect   以极低的性能开销仅跟踪收集GC</span><br></pre></td></tr></table></figure><p>您可以使用dotnet-trace命令,在Linux上收集跟踪信息.</p><p><strong><code> dotnet trace collect -p &lt;pid&gt; -o &lt;outputpath&gt; --profile gc-collect</code></strong></p><p>然后在Windows上用PerfView进行展示.当您查看GCStats视图时,从使用者的角度来看,与使用PerfView收集唯一的不同是:在Windows进行收集跟踪,您可以看到所有的托管线程.而在Linux收集跟踪则只会包含您指定PID的线程.</p><p>在这篇文章中,我将重点介绍您看到的GCStats表格.我会展示一个例子.流程的第一张表:“GC Rollup By Generation” –</p><p><img src="/img/WorkFlow-GCRollupByGeneration.png" alt="WorkFlow-GCRollupByGeneration"></p><p>我忽略了<code>Alloc MB/MSec GC</code>与<code>Survived MB/MSec GC</code>这两列 – 他们在我开始使用PerfView之前就已经存在了,如果能把他们修复一下,让它们更有意义就更好了,但我一直没有处理.</p><p>如果您想进行一个例行的分析,通常意味着您没有一个直接的目标,您只想看看是否有可以改进的地方,可以从<code>Rollup</code>表开始.</p><p>如果我查看上一个表,我马上就会注意到gen2的平均中断时间比gen0/1的GC大得多.我可以猜测这些<code>二代堆GC</code>可能没有经历过中断,因为<code>Max Peak MB(最大峰值MB)</code>大约为13GB,如果我要遍历所有的内存,大概要花费167ms.所以,这些可能是后台GC(Background GC),这一点在<code>Rollup</code>表下方的 “Gen 2 for pid: process_name” 表中得到了确认 (我删除了一些列,这样就不会太宽了) –</p><p><img src="/img/WorkFlow-GCRollupByGeneration2.png" alt="WorkFlow-GCRollupByGeneration2"></p><p>2B表示在后台执行的二代堆GC.如果您想知道还有哪些组合,只需将鼠标悬停在”Gen”的列标题上,将显示以下文字:</p><p><strong><code>N=NonConcurrent/非并发式GC, B=Background/后台GC, F=Foreground/前台GC (一直以后台GC运行) I=Induced/触发式GC i=InducedNotForced/触发非前台</code></strong></p><ul><li>N=NonConcurrent/非并发式GC</li><li>B=Background/后台GC</li><li>F=Foreground/前台GC (一直以后台GC运行)</li><li>I=Induced/触发式GC</li><li>i=InducedNotForced/触发非前台</li></ul><p>所以对于<code>二代堆GC</code>,您可能会看到2N, 2NI, 2Ni or 2Bi.如果您使用GC.Collect来触发GC,它有两个采用此参数的重载 –</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bool blocking</span><br></pre></td></tr></table></figure><p>除非您将该参数指定为False,它意味着将始终以阻塞的方式触发GC.这就是为什么没有2BI的原因</p><p>在rollup表中,始终有一列<code>Induced</code>显示为0 ,但如果这不是0,特别是当与GC的总数相比时是一个相当大的数字时,找出是谁在触发这些GC是一个非常好的主意.这在这篇<a href="https://devblogs.microsoft.com/dotnet/gc-etw-events-2/">博客</a>中做了详细的讲解.</p><p>所以,我知道了这些GC总数全部来源于BGC,但是,对于BGC来说,这些中断的时间太长了! </p><p>请注意,虽然我将两次中断显示成了一次,但它实际是由两次中断组成的.在<a href="https://docs.microsoft.com/en-us/dotnet/standard/garbage-collection/media/fundamentals/background-workstation-garbage-collection.png">这张来自于GC MSDN的图片</a>中,显示了一次BGC中的两次中断(蓝色的列所指的位置).</p><p>但是,您在GCStats中看到的中断时间是这两次中断的总和.原因是最初的中断通常都非常短(图片中的蓝色列仅用于举例-它们并不代表实际上真正用了多长时间). 在这种情况下,我想看每个单独的中断花费了多长时间 - 我正在考虑在GLAD中提供各个BGC的中断信息,但在这之前,您可以自己弄清楚.</p><p>在<a href="https://devblogs.microsoft.com/dotnet/gc-etw-events-3/">这篇博客中</a>,我描述了BGC在触发事件时的顺序.所以我需要找到两次<code>SuspendEE/RestartEE</code>事件.</p><p>要做到这一点,您可以在Perfview中打开<code>“Events”</code>视图,然后从<code>“Pause Start”</code>开始.</p><p>让我以GC#9217为例,它的首次中断在789,274.32 您可以在“Start”输入框中输入它.然后在“Process Filter”中输入“gc/”,仅过滤GC事件,然后选择SuspendEE/RestartEE/GCStart/GCStop事件,摁下回车.</p><p>下面是此时您将会看到的示例图片(处于隐私原因,我删除了进程名字) -<br><img src="/img/WorkFlow1-0.jpg" alt="WorkFlow1-0"></p><p>这就是首次发生中断的地方,如果您选择首次SuspendEEStart和首次RestartEEStop的时间戳,我可以看到在这个视图的状态栏上显示了两个时间戳的差异是75.902.这已经非常长了 -通常来说,首次中断时间每组都应当不超过几毫秒.对于这种情况,您基本上可以将其交给我,因为在我的设计中,不应该出现这种情况.</p><p>但是,如果您有兴趣自己继续诊断,下一步是捕获更多的事件跟踪,来向我展示挂起期间发生了什么.通常,我捕获的跟踪是CPU事件样本+GC的事件跟踪.CPU样本清楚的向我展示了真正的罪魁祸首.其实并不是在GC中,而是运行时中的其他东西.后来我已经修复了,这个性能问题只有在您的程序中有多个模块时才会发生(在这个特殊的场景下,客户拥有数千个模块).</p><p>第二次的BGC中断从SuspendEEStart事件,原因是“SuspendForGCPrep”,与第一次的SuspendEESrart事件不同的是,此次原因是“SuspendForGC”.</p><p>由GC为目的引发的停顿,仅有两个可能,而“SuspendForGCPrep”仅在初次中断的BGC期间可用.</p><p>通常来说,一个BGC仅会有两次中断,但如果您启用了<code>GCHeapSurvivalAndMovementKeyword</code>事件,您将在BGC期间添加第三个中断,因为要触发这些事件,托管线程必须处于中断状态.如果是这种情况,第三次暂停也会有“SuspendForGCPerp”原因,并且通常比其他两个中断要长的多.因为堆如果很大,触发事件将花费很长的时间.</p><p>我见过很多这种情况,当大家根本不需要这些事件时,却看到BGC的中断时间被人为的拉长.原因正是这个.</p><p>您可能会问,既然不需要这些事件,为什么还会不小心的收集到这些事件.这是因为您在收集运行时事件时,它们已经包含在默认值中(您可以在src\TraceEvent\Parsers\ClrTraceEventParser.cs中看到默认值中包含的关键字,搜索default.您会看到许多关键字被包含在了默认值中).</p><p>一般来说,我认为PerfView的理念是,默认情况下应当收集足够的事件提供给您以便进行调查.在一般情况下,这都是一个很好的策略,因为您可能无法对问题进行复现.但是您需要通过收集事件本身来判断,什么是由于收集事件引发的,什么是由于产品引发的.</p><p>当然,这是在建立在您有能力收集这么多事件的基础上.有时绝对不是这种情况.这就是为什么我通常要求人们从轻量级跟踪开始,来向我表明这里是否存在问题,以及如果存在问题,我还需要收集哪些事件.</p><p>我从gen2表注意到了的另一件事,所有的BGC都是由AllocLarge触发的.可能被触发的原因定义为GCReason:</p><ul><li><a href="https://github.com/microsoft/perfview/blob/master/src/TraceEvent/Parsers/ClrTraceEventParser.cs">src\TraceEvent\Parsers\ClrTraceEventParser.cs</a></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">GCReason</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    AllocSmall = <span class="number">0x0</span>,</span><br><span class="line">    Induced = <span class="number">0x1</span>,</span><br><span class="line">    LowMemory = <span class="number">0x2</span>,</span><br><span class="line">    Empty = <span class="number">0x3</span>,</span><br><span class="line">    AllocLarge = <span class="number">0x4</span>,</span><br><span class="line">    OutOfSpaceSOH = <span class="number">0x5</span>,</span><br><span class="line">    OutOfSpaceLOH = <span class="number">0x6</span>,</span><br><span class="line">    InducedNotForced = <span class="number">0x7</span>,</span><br><span class="line">    Internal = <span class="number">0x8</span>,</span><br><span class="line">    InducedLowMemory = <span class="number">0x9</span>,</span><br><span class="line">    InducedCompacting = <span class="number">0xa</span>,</span><br><span class="line">    LowMemoryHost = <span class="number">0xb</span>,</span><br><span class="line">    PMFullGC = <span class="number">0xc</span>,</span><br><span class="line">    LowMemoryHostBlocking = <span class="number">0xd</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最常见的原因是<code>AllocSmall</code>,意味着您在<code>SOH(Small Object Heap)</code>的分配触发了GC.而<code>AllocLarge</code>意味着<code>LOH(Long Object Heap)</code>的分配触发了GC. </p><p>在这种特殊下团队已经意识到,他们正在进行大量的LOH分配 – 但他们可能不知道会经常导致BGC.</p><p>如果您查看“Gen2 Survival Rate %”列,您会注意到二代的存活率非常高(97%),但是“LOH Survival Rate %(LOH存活率 %)”却非常低-29%</p><p>这告诉了我,有许多的LOH分配存活的相当短.我会根据gen2的预算调整LOH的预算(分配量阈值),因此在这种情况下,我不会过多的触发gen2的GC.</p><p>如果我想提高LOH的存活率,我需要比这更加频繁的触发BGC.如果您很清楚您的LOH的分配通常是临时的,那么通过GCLOHThreshold的配置增大LOH的阈值就是一个不错的办法.</p><p>这就是今天的全部内容了.下次我将讨论GCStats视图中更多表.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;原文为Maoni发布在Microfost Blog中的,诊断性能问题的工作流程系列.&lt;br&gt;目前共更新三章.在本章中,Maoni介绍了一些在进行性能诊断时的操作与分析.&lt;/p&gt;</summary>
    
    
    
    <category term="C#" scheme="http://murph.site/categories/C/"/>
    
    
    <category term="C#" scheme="http://murph.site/tags/C/"/>
    
    <category term="性能诊断" scheme="http://murph.site/tags/%E6%80%A7%E8%83%BD%E8%AF%8A%E6%96%AD/"/>
    
    <category term="Maoni" scheme="http://murph.site/tags/Maoni/"/>
    
    <category term="PerfView" scheme="http://murph.site/tags/PerfView/"/>
    
  </entry>
  
</feed>
