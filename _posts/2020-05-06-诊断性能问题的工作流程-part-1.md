---
layout: post
title: 诊断性能问题的工作流程 – Part 1
date: 2020-05-06 22:05 +0800
---

Creater:        [@Maoni Stephens](https://twitter.com/maoni0)

Translator:     @Shaun Murphy

Proofreader：待定

> [原文链接](https://devblogs.microsoft.com/dotnet/work-flow-of-diagnosing-memory-performance-issues-part-0)

---
# 作者授权

![authorize]({{ site.baseurl }}/1587561145552-0d8a560c-3b7d-443a-badc-a98ddbb6e7bf.png)

> 未经原作者允许以及保护隐私，这里将maoni大佬的邮箱地址隐去了，如果想要与原作者取得联系，请在原文的下方进行留言。

## 译者按

如果这篇文章可以帮到您，那么这将是我最大的一份荣幸，但也请您点进原文，给原作者一个善意的回复，或在文章下方留下善意的回复，您的支持将是这些可敬的社区磐石保持创作激情中最大的一部分:)

<b>中文版本将不会以任何形式收费，所有版权归属与原作者</b>

原作者Twitter：[https://twitter.com/maoni0](https://twitter.com/maoni0)

原作者Github：[https://github.com/Maoni0](https://github.com/Maoni0)

---
## 正文

In this blog post I’ll talk a bit about contributing to PerfView and then continue with the GCStats analysis. You can [skip to the analysis part](https://devblogs.microsoft.com/dotnet/work-flow-of-diagnosing-memory-performance-issues-part-1/#continuing-the-analysis) directly if you like.

One of the frustrating things for me when it comes to tooling is there are a lot of memory perf tools out there but very few are targeting the common types of customers I normally work with. Every tool does the basics; very few do intermediate and advanced analysis. I know folks have complained about the usability of PerfView – and I do think some of the complaints are valid. None the less I love PerfView because it’s often the only tool that can get the job done. I hope folks understand that 1) we have very limited resource for PerfView (we don’t have a whole tooling team like in the Visual Studio org; we have part time from a few individuals) so it’s hard to satisfy nearly all user requests; 2) when it comes to advanced analysis, since it can be so diverse, it naturally means the usability is not going to be as straightforward – when there are so many ways to look at things, the permutation quickly becomes very large.

Contributing to something like PerfView is an excellent way to contribute to .NET core. It doesn’t have as steep of a learning curve as the runtime itself but your contribution could potentially save people a ton of time. You can start by cloning the [repo](https://github.com/microsoft/perfview/) and building it. And then you can step through the code – IMO if you could actually step through the code, this is always the best way to understand something new. The code that affects what I talk about here mostly lives in 2 files – src\TraceEvent\Computers\TraceManagedProcess.cs and src\PerfView\GcStats.cs. If you search for things like Clr.EventName (eg, Clr.GCStart, Clr.GCStop), that’s where the events are analyzed (you don’t have to be concerned with the actual parsing the trace part – that’s handled elsewhere). So the GC analysis done in this file is what we call our [GLAD](https://devblogs.microsoft.com/dotnet/glad-part-2/) (GC Latency Analysis and Diagnostics) library. And GcStats.cs uses it to display what you see in the GCStats view which is an html file. If you’d like to display the GC related info in your own tools, GCStats.cs would serve as an excellent example how to use GLAD.

### Continuing the analysis

In the last post we talked about collecting a GCCollectOnly trace and inspecting the GCStats view in PerfView that’s enabled by the GC events collected. And I should note that you can do this on Linux as well with dotnet-trace. From its doc: one of the built in profiles it offers is what’s equivalent to the /GCCollectOnly arg to PerfView’s collect command:

```
 --profile

   [omitted]

   gc-collect   Tracks GC collection only at very low overhead

```

You can collect a trace with dotnet-trace on Linux with this commandline

<span style="color:red">dotnet trace collect -p <pid> -o <outputpath> --profile gc-collect</span>

and view it on Windows with PerfView. The only difference from the user’s POV when you view the GCStats view is, with the trace collected on Windows you will see all the managed processes whereas the trace collected on Linux only has the process with the pid you specified.

In this blog post I will focus on the tables you see in GCStats. I’m showing an example here. The 1st table for a process is the “GC Rollup By Generation” table –

<div class="table-responsive"><table><thead><tr><th class=""></th><th class=""></th><th>GC</th><th>Rollup</th><th>By</th><th>Generation</th><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>Gen</td><td>Count</td><td>Max Pause</td><td>Max Peak MB</td><td>Max Alloc MB/sec</td><td>Total Pause</td><td>Total Alloc MB</td><td>Alloc MB/ MSec GC</td><td>Survived MB/ MSec GC</td><td>Mean Pause</td><td>Induced</td></tr><tr><td>ALL</td><td>130</td><td>173.2</td><td>13,073.7</td><td>1,131.804</td><td>4,336.1</td><td>167,910.9</td><td>38.7</td><td>24.686</td><td>33.4</td><td>0</td></tr><tr><td>0</td><td>60</td><td>51.0</td><td>12,992.7</td><td>806.553</td><td>1,410.8</td><td>88,958.3</td><td>0.0</td><td>∞</td><td>23.5</td><td>0</td></tr><tr><td>1</td><td>62</td><td>48.3</td><td>13,073.7</td><td>422.930</td><td>1,585.0</td><td>77,866.1</td><td>0.0</td><td>∞</td><td>25.6</td><td>0</td></tr><tr><td>2</td><td>8</td><td>173.2</td><td>12,730.3</td><td>1,131.804</td><td>1,340.3</td><td>1,086.5</td><td>0.0</td><td>4,169.493</td><td>167.5</td><td>0</td></tr></tbody></table></div>