---
layout: post
title: 诊断性能问题的工作流程 – Part 0 (翻译中)
date: 2020-05-06 22:05 +0800
---

Creater:        [@Maoni Stephens](https://twitter.com/maoni0)

Translator:     @Shaun Murphy

Proofreader：待定

> [原文链接](https://devblogs.microsoft.com/dotnet/work-flow-of-diagnosing-memory-performance-issues-part-0)

---
# 作者授权

![authorize]({{ site.baseurl }}/images/1587561145552-0d8a560c-3b7d-443a-badc-a98ddbb6e7bf.png)

> 未经原作者允许以及保护隐私，这里将maoni大佬的邮箱地址隐去了，如果想要与原作者取得联系，请在原文的下方进行留言。

## 译者按

如果这篇文章可以帮到您，那么这将是我最大的一份荣幸，但也请您点进原文，给原作者一个善意的回复，或在文章下方留下善意的回复，您的支持将是这些可敬的社区磐石保持创作激情中最大的一部分:)

<b>中文版本将不会以任何形式收费，所有版权归属与原作者</b>

原作者Twitter：[https://twitter.com/maoni0](https://twitter.com/maoni0)

原作者Github：[https://github.com/Maoni0](https://github.com/Maoni0)

---
## 正文

我想描述以下,我在诊断性能问题时,所进行的工作流程,更确切的说,是在进行此类诊断时的一些共同部分.诊断性能问题没有固定的步骤,可以采取多种方式,但我将尝试将其分解为可用于各种诊断的一些基本模块

本章节适用于初学者,因此,如果您已经具备了一些内存分析的经验,则可以安全的跳过本章;

首先,在我们进行实际的诊断部分之前,有必要了解一些可以指导您正确方向的一些高级知识;

1) 时间点 Vs 直方图

至关重要的一点,了解内存问题发生在什么时间点上.内存问题通常不会忽然出现,而是可能需要一段时间的累计,才会发展到足以引起注意的程度.

让我们举一个简单的例子,对于一个非常简单的不区分代的GC,它只会紧凑的阻塞GC, this is still the case. 如果您刚刚从GC中退出,那么堆大小当然处在最小的时间点.如果您碰巧在这个时间点进行测量,您会认为“很棒;我的堆很小”.但是,如果您恰好在下一个GC之前进行测量,那么堆可能会变得相当大,并且您会有一些不同的看法(比如某些基础类库或者对象错误的占用了堆中绝大部分的空间).这仅仅是适用于简单的GC,请想象一下,如果在区分代的GC或并发式GC的场景中,那么将会发生什么.

这也是为什么,了解GC的历史,了解GC是如何做出的决策,以及这些决策将导致什么情况出现,在诊断内存问题中是如此重要的原因.

不幸的是,许多内存工具与诊断方法都没有考虑到这一点.他们进行内存诊断的方法是“让我告诉您,您碰巧要问的那个堆的情况”.这通常无济于事,有时甚至完全的误导了人们,浪费了时间去追逐一个不存在的问题,或者在这个错误的问题上取得一些完全错误的进展.这并不是说这样的工具根本没有任何帮助-当问题很简单时,他们可能会有所帮助.但如果您已经经历了一段时间的严重内存泄漏,并且使用了一个可以在此时显示堆的工具(通过执行进程转储,使用SOS,或另一种转储堆的工具)

2) 分代GC

按照设计,分代代GC在触发时.不会收集整个堆.它尝试对年轻一代进行GC的频率要高于堆老一代GC的频率.堆老一代进行GC,通常来说成本会更高.使用并发堆旧式GC时,STW的时间不会很长,但是GC仍然需要花费一整个CPU的时钟来完成其工作.

This also makes looking at the heap much more complicated because if you are fresh out of an old gen GC, especially a compacting one, you obviously have a potentially way smaller heap size than if you were right before that GC is triggered; but if you look at young gen GCs, they could be compacting but the difference is heap size isn’t as much and that’s by design.

3) Compacting vs sweeping

Sweeping is not supposed to change the heap size by much. In our implementation we still give up the space at the end of segments so the total heap size can become a bit smaller but as high level you can think of the total heap size as not changing but free spaces get built up in order to accommodate the allocations from a younger gen (or in gen0/LOH case user allocations).

So if you see 2 gen2 GCs, one is compacting and the other is sweeping, it’s expected if the compacting one comes out with a much smaller heap size and the other one with high fragmentation (by design as that’s the free list we built up).

4) Allocation and survival

While many memory tools report allocations, it’s not just allocations that cost. Sure, allocations can trigger GCs, and that’s definitely a cost but when GC is working, the cost is mostly dominated by survivals. Of course you cannot be in a situation that both your allocation rate and survival rate are very high – you’d just run out of memory very quickly.

5) “Mainline GC scenario” vs “not mainline”

If you had a program that just used the stack and created some objects to use, GC has been optimizing that for years and years. Basically “scan stacks to get the roots and handle the objects from there”. This is the mainline GC scenario that many GC papers assume as the only scenario. Of course as a commercial product that has existed for decades and having to accommodate various customer requests, we have a bunch of other things like GC handles and finalizers. The important thing to understand there is while over the years we also optimized for those, we operate based on assumptions that “there aren’t too many of those” which obviously is not true for everyone. So if you do have many of those, it’s worth looking at if you are diagnosing a memory problem. In other words, if you don’t have any memory problem, you don’t need to care; but if you do (eg, high % time in GC), they are good things to suspect.

All this info is expressed in ETW events or the equivalent on Linux – this is why for years we’ve been investing in them and the tooling for analyzing the traces.

Traces to capture to start with

I often ask for 2 traces to start with. The 1st one is to get the accurate GC timing:

<span style="color:red">perfview /GCCollectOnly /nogui collect</span>

after you are done, press s in the perfview cmd window to stop it

This should be run long enough to capture enough GC activities, eg, if you know problems occur at times, this should cover time that leads up to when problems happen (not only during problematic time).

If you know how long to run it for you can do (this is used much more often actually) –

<span style="color:red">perfview /GCCollectOnly /nogui /MaxCollectSec:1800 collect</span>

eplace 1800 (half an hour) with however many seconds you need.

This collects the informational level of GC events and just enough OS events to decode the process names. This command is very lightweight so it can be on all the time.

Notice I have the /nogui in all the PerfView commandlines I give out. PerfView does have a UI for event collection that allows you to select the events you want to capture. Personally I never use it (after I used it a couple of times when I first started to use PerfView). Some of it is just because I’m much more a commandline person; the other (important) part is because commandlines allow for much more flexibility and are a lot more automation friendly.

After you collect the trace you can open it in PerfView and look at the GCStats view. Some folks tend to just send it to me after they are done collecting but I would really encourage everyone who needs to do memory diagnostics on a regular basis to learn to read this view ’cause it’s very useful. It gives us a wealth of information, even though the trace so lightweight. And if this doesn’t get us to the root cause, it definitely points at the direction we should take to make more progress. I described some of this view in [this blog entry](https://devblogs.microsoft.com/dotnet/gc-etw-events-1/) and its sequels that are linked in the entry. So I’m not going to show more pictures here. You could easily open that view and see for yourself.

Examples of the type of issues that can be easily spotted with this view –

* Very high “% Time paused for garbage collection”. Unless you are doing some microbenchmarking and specifically testing allocation perf (like many GC benchmarks), you should not see this as higher than a few percent. If you do that’s something to investigate. Below are things that can contribute to this percentage significantly.

* Individual GCs with unusually long pauses. Is a 60s GC really long? Yes you bet it is! And this is usually largely not due to GC work. From my experience it’s always due to something interfering with the GC threads.

* Excessively induced GCs (high ratio of (# of induced GCs / total # of GCs), especially when the induced GCs are gen2s.

* Excessive # of gen2 GCs – gen2 are costly especially when you have a large heap. Even though with BGC, most of its work is done concurrently, it’s still CPU cycles spent so if you have every other GC as gen2, that usually immediately points at a problem. One obvious case is most of them are triggered with the AllocLarge trigger reason. Again, there are cases where this is necessarily not a problem, for example if most of your heap is LOH and you are not running inside a container, which means LOH is not compacted by default, in that case doing gen2s just sweeps the LOH and that’s pretty quick.

* Long suspension issues – suspension usually should take much less than 1ms, if it takes 10s of ms that’s a problem; if it takes hundreds of ms, that’s definitely a problem.

* Long suspension issues – suspension usually should take much less than 1ms, if it takes 10s of ms that’s a problem; if it takes hundreds of ms, that’s definitely a problem.

Those are just things you can see at a glance. If you dig a little deeper there are many more things. And we’ll talk about them next time.







