---
layout: post
title: 诊断性能问题的工作流程 – Part 0 (翻译中)
date: 2020-05-06 22:05 +0800
---

Creater:        [@Maoni Stephens](https://twitter.com/maoni0)

Translator:     @Shaun Murphy

Proofreader：待定

> [原文链接](https://devblogs.microsoft.com/dotnet/work-flow-of-diagnosing-memory-performance-issues-part-0)

---
# 作者授权

![authorize]({{ site.baseurl }}/images/1587561145552-0d8a560c-3b7d-443a-badc-a98ddbb6e7bf.png)

> 未经原作者允许以及保护隐私，这里将maoni大佬的邮箱地址隐去了，如果想要与原作者取得联系，请在原文的下方进行留言。

## 译者按

如果这篇文章可以帮到您，那么这将是我最大的一份荣幸，但也请您点进原文，给原作者一个善意的回复，或在文章下方留下善意的回复，您的支持将是这些可敬的社区磐石保持创作激情中最大的一部分:)

<b>中文版本将不会以任何形式收费，所有版权归属与原作者</b>

原作者Twitter：[https://twitter.com/maoni0](https://twitter.com/maoni0)

原作者Github：[https://github.com/Maoni0](https://github.com/Maoni0)

---
## 正文

我想描述以下,我在诊断性能问题时,所进行的工作流程,更确切的说,是在进行此类诊断时的一些共同部分.诊断性能问题没有固定的步骤,可以采取多种方式,但我将尝试将其分解为可用于各种诊断的一些基本模块

本章节适用于初学者,因此,如果您已经具备了一些内存分析的经验,则可以安全的跳过本章;

首先,在我们进行实际的诊断部分之前,有必要了解一些可以指导您正确方向的一些高级知识;

1) 时间点 Vs 直方图

至关重要的一点,了解内存问题发生在什么时间点上.内存问题通常不会忽然出现,而是可能需要一段时间的累计,才会发展到足以引起注意的程度.

让我们举一个简单的例子,对于一个非常简单的不区分代的GC,它只会中断GC的压缩, this is still the case. 如果您刚刚从GC中退出,那么堆大小当然处在最小的时间点.如果您碰巧在这个时间点进行测量,您会认为“很棒;我的堆很小”.但是,如果您恰好在下一个GC之前进行测量,那么堆可能会变得相当大,并且您会有一些不同的看法(比如某些基础类库或者对象错误的占用了堆中绝大部分的空间).这仅仅是适用于简单的GC,请想象一下,如果在区分代的GC或并发式GC的场景中,那么将会发生什么.

这也是为什么,了解GC的历史,了解GC是如何做出的决策,以及这些决策将导致什么情况出现,在诊断内存问题中是如此重要的原因.

不幸的是,许多内存工具与诊断方法都没有考虑到这一点.他们进行内存诊断的方法是“让我告诉您,您碰巧要问的那个堆的情况”.这通常无济于事,有时甚至完全的误导了人们,浪费了时间去追逐一个不存在的问题,或者在这个错误的问题上取得一些完全错误的进展.这并不是说这样的工具根本没有任何帮助-当问题很简单时,他们可能会有所帮助.但如果您已经经历了一段时间的严重内存泄漏,并且使用了一个可以在此时显示堆的工具(通过执行进程转储,使用SOS,或另一种转储堆的工具)

2) 分代GC

按照设计,分代GC在触发时.不会收集整个堆.它尝试对新生代进行GC的频率要高于对老年代GC的频率.对老年代进行GC,通常来说成本会更高.使用并发的旧式GC时,STW的时间不会很长,但是GC仍然需要花费一整个CPU的时钟来完成其工作.

<!-- `todo` 这段翻译的并不好,考虑一下重构.感觉作者想表达的应该是,对老年代与新生代GC的差别

This also makes looking at the heap much more complicated because if you are fresh out of an old gen GC, especially a compacting one, you obviously have a potentially way smaller heap size than if you were right before that GC is triggered; but if you look at young gen GCs, they could be compacting but the difference is heap size isn’t as much and that’s by design. -->

这也使查看堆变得复杂.因为如果您刚刚从老年代的GC中退出,特别是刚经历过压缩的情况下.显然,与触发GC之前相比,堆的大小可能会变得更小.但是,如果您查看新生代的GC,他们可能经历过压缩,但区别在于,堆大小不会那么大.这是GC的设计决定的.


3) 压缩 vs 清除

清除不应该太大的改变堆大小. 在我们的实现中,我们仍然放弃了一些堆段末尾的空间.所以,堆的总大小可能会变小.但从`High Level`,您可以认为堆的总大小没有发生变化.但是自由空间会建立来容纳新生代的分配(gen0/LOH)

<!-- So if you see 2 gen2 GCs, one is compacting and the other is sweeping, it’s expected if the compacting one comes out with a much smaller heap size and the other one with high fragmentation (by design as that’s the free list we built up). -->

因此,如果你能看到有两个gen2 GC,一个正在进行压缩而另一个正在进行清除.则可以预期.如果压缩后的堆变得非常小,另一个的则会变得具有高度的碎片化(这是我们所涉及的自由列表`Free list`)

4) 分配 and 存活

尽管许多内存工具都会报告分配情况,但它不仅仅只是分配的成本.

当然,分配会触发GC,这无疑是成本,但是GC什么时候开始工作,则大多数取决于存活率.当然您不能长时间取决于分配率与生存率都非常高的情况下-您很快就会耗尽内存.

5) 主流的垃圾回收” vs “非主流”

如果您有一个程序仅使用了堆并创建了一些对象,`Years and years`,GC一直在它.

基本上"扫描堆来获取根与引用的对象在哪里".这是许多GC论文都将其视为唯一方案的主线GC方案.

当然,作为一个存在了数十年的商业产品,必须满足客户的各种需求.我们还有很多其他东西,例如`GC Handles(GC 句柄)`和`finalizers(终结器)`

需要了解的重要事情是，多年来，我们还针对这些问题进行了优化

我们基于以下假设 `“there aren’t too many of those”`,显然这不适用于所有人,So if you do have many of those, 如果您正在诊断内存问题,则它们是值得一看的.

换一种说法,如果您没有任何的内存问题,您不需要关心它们.但是如果您遇到了(长时间GC),他们是值得怀疑的.

所有的这些信息都表示为ETW事件,或Linux上的等效事件.这就是为什么我们多年来一直投资与它们与分析痕迹的工具上面的原因.

<b>开始追踪痕迹</b>

我通常会从两条痕迹开始,第一条是获取到准确到GC时间点

<span style="color:red">perfview /GCCollectOnly /nogui collect</span>

完成后，在perfview cmd窗口中按s以将其停止

This should be run long enough to capture enough GC activities, eg, if you know problems occur at times, this should cover time that leads up to when problems happen (not only during problematic time).

If you know how long to run it for you can do (this is used much more often actually) –

<span style="color:red">perfview /GCCollectOnly /nogui /MaxCollectSec:1800 collect</span>

eplace 1800 (half an hour) with however many seconds you need.

This collects the informational level of GC events and just enough OS events to decode the process names. This command is very lightweight so it can be on all the time.

Notice I have the /nogui in all the PerfView commandlines I give out. PerfView does have a UI for event collection that allows you to select the events you want to capture. Personally I never use it (after I used it a couple of times when I first started to use PerfView). Some of it is just because I’m much more a commandline person; the other (important) part is because commandlines allow for much more flexibility and are a lot more automation friendly.

After you collect the trace you can open it in PerfView and look at the GCStats view. Some folks tend to just send it to me after they are done collecting but I would really encourage everyone who needs to do memory diagnostics on a regular basis to learn to read this view ’cause it’s very useful. It gives us a wealth of information, even though the trace so lightweight. And if this doesn’t get us to the root cause, it definitely points at the direction we should take to make more progress. I described some of this view in [this blog entry](https://devblogs.microsoft.com/dotnet/gc-etw-events-1/) and its sequels that are linked in the entry. So I’m not going to show more pictures here. You could easily open that view and see for yourself.

Examples of the type of issues that can be easily spotted with this view –

* Very high “% Time paused for garbage collection”. Unless you are doing some microbenchmarking and specifically testing allocation perf (like many GC benchmarks), you should not see this as higher than a few percent. If you do that’s something to investigate. Below are things that can contribute to this percentage significantly.

* Individual GCs with unusually long pauses. Is a 60s GC really long? Yes you bet it is! And this is usually largely not due to GC work. From my experience it’s always due to something interfering with the GC threads.

* Excessively induced GCs (high ratio of (# of induced GCs / total # of GCs), especially when the induced GCs are gen2s.

* Excessive # of gen2 GCs – gen2 are costly especially when you have a large heap. Even though with BGC, most of its work is done concurrently, it’s still CPU cycles spent so if you have every other GC as gen2, that usually immediately points at a problem. One obvious case is most of them are triggered with the AllocLarge trigger reason. Again, there are cases where this is necessarily not a problem, for example if most of your heap is LOH and you are not running inside a container, which means LOH is not compacted by default, in that case doing gen2s just sweeps the LOH and that’s pretty quick.

* Long suspension issues – suspension usually should take much less than 1ms, if it takes 10s of ms that’s a problem; if it takes hundreds of ms, that’s definitely a problem.

* Long suspension issues – suspension usually should take much less than 1ms, if it takes 10s of ms that’s a problem; if it takes hundreds of ms, that’s definitely a problem.

Those are just things you can see at a glance. If you dig a little deeper there are many more things. And we’ll talk about them next time.







